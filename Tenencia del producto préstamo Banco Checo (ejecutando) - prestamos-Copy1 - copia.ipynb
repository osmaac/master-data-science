{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tenencia del producto préstamo en el DataSet de Banca Checo  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a intentar extraer del datset generado que variables son las más relevantes para que una cuenta (account) haya contratado un péstamo (loan) y ver si de esta forma podemos generar un customer journey para conseguir que un cliente contrate un préstamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.core.multiarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para bajarlo directamente de GitHub\n",
    "#url=\"https://raw.githubusercontent.com/osmaac/master-data-science/master/DFTenenciaProductos.csv\"\n",
    "#df_original=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos que hemos procesado en R\n",
    "df_original= pd.read_csv(\"C://Master Data Science/Master en Data Science/TFM/Transacciones de Banco Checo/DFTenenciaProductos_wo_LoanPayment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzamos a revisar que el DF se haya importado correctamente\n",
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a analizar si hay missings al cargar los datos a Python\n",
    "df_original.columns[df_original.isnull().sum()!=0]\n",
    "#Vemos que las variables con missings provienen de variables que ya tenían esos missings en el DataFrame generado con R,\n",
    "#ya que el disponent (autorizado), los préstamos y las tarjetas no son productos que tengan asociados \n",
    "#todas las cuentas (sólo las cuentas que los hayan contratado) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos como se han importado las variables del DataFrame de R al DataFrame que vamos a utilizar en Python \n",
    "print(df_original.iloc[:,0:32].dtypes)\n",
    "print(df_original.iloc[:,31:61].dtypes)\n",
    "print(df_original.iloc[:,60:70].dtypes)\n",
    "#Observamos que las variables de factor y de fecha han modificado su tipo de variable, \n",
    "#por lo que tendremos que trabajar con ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos a formato fecha las variables que originalmente eran fecha en R\n",
    "df_original[[\"Date_Account\",\"birth_owner\", \"birth_disponent\", \"Date_Loan\", \"owner_card_date\"]]=df_original[[\"Date_Account\",\"birth_owner\", \"birth_disponent\", \"Date_Loan\", \"owner_card_date\"]].apply(pd.to_datetime)\n",
    "from datetime import datetime\n",
    "df_original['Date_Account']=df_original['Date_Account'].apply(datetime.toordinal)\n",
    "df_original['birth_owner']=df_original['birth_owner'].apply(datetime.toordinal)\n",
    "df_original['birth_disponent']=df_original['birth_disponent'].apply(datetime.toordinal)\n",
    "df_original['Date_Loan']=df_original['Date_Loan'].apply(datetime.toordinal)\n",
    "df_original['owner_card_date']=df_original['owner_card_date'].apply(datetime.toordinal)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De todas las variables de las que disponemos, vamos a seleccionar las que vamos a utilizar en este ejercicio:\n",
    "\n",
    "La  variable que vamos a predecir va a ser \"account_loan_bin\" y por tanto la denominaremos \"y\"\n",
    "\n",
    "Para este ejercicio no consideramos las variables que hemos obtenido en el mismo fichero que la variable a predecir (loan.csv):\n",
    "loan_id, Date_Loan, Amount_Loan, Duration_Loan, Payments_Loan, status, Status_Loan.\n",
    "\n",
    "Otras variables que no consideramos: account_id, client_id_owner, client_id_disponent, district ID y unnamed:0 porque \n",
    "son ID's descriptivas sin información para utilizar\n",
    "\n",
    "La variable disponent_card_type no aporta información, ya que no hay autorizados que hayan contratado card (tarjeta)\n",
    "\n",
    "Otras variables que no consideramos:district_name, region (nombre). Utilizamos el resto de la información de variables \n",
    "del fichero district.csv, que fundamentalemente aportan datos socio-económicos\n",
    "\n",
    "Haciendo referencia a district.csv , la información de crimes_95, crimes_96 y entrepreneurs la vamos a utilizar como ratio,\n",
    "ya que como veremos a continuación, de esta forma el número de habitantes del distrito Praga no distorsiona los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Las variables crimes_95, crimes_96 y entrepreneurs vamos a utilizarlas en formato ratio, tal y como calculamos en R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_95'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_95_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_96'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_96_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['entrepreneurs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['entrepreneurs_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame con las variables que vamos a considerar numéricas\n",
    "df_num=df_original[['Date_Account','birth_owner', 'birth_disponent','owner_card_date','Ord_Insurance', 'Ord_Insurance_amount',\n",
    "                    'Ord_Household_Payment','Ord_Household_Payment_amount', 'Ord_Loan_Payment', 'Ord_Leasing',\n",
    "                    'Ord_Empty', 'Ord_Empty_amount', 'num_inhabitants', 'municip < 499', 'municip 500-1999',\n",
    "                    'municip 2000-9999', 'municip > 10000', 'num_cities', 'avg_salary',  \n",
    "                    'Num_Type_Credit', 'Num_Type_VYBER', 'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances',\n",
    "                    'Num_Op_Collection','Num_Op_CashCredit', 'Num_Op_WithdrawalCash','Num_Op_WithdrawalCreditCard',\n",
    "                    'Num_Sym_Null', 'Num_Sym_Null2','Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal',\n",
    "                    'Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep', 'Num_Sym_LoanPayment', \n",
    "                    'Balance_in_negative','Ord_Loan_Payment_amount', 'Ord_Leasing_amount','ratio_urban_inhabitants',\n",
    "                    'unemployment_rate_95','unemployment_rate_96', 'crimes_95_ratio', 'crimes_96_ratio', 'entrepreneurs_ratio' ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame con las variables que vamos a considerar categóricas\n",
    "df_cat=df_original[['account_disponent_bin','frequency', 'sex_owner', 'owner_card_type',\n",
    "       'sex_disponent']]\n",
    "#Vemos que tipos tienen las variables que queremos que sean categóricas\n",
    "df_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ponemos las variables \"owner_card_type\" y \"account_disponent_bin\" como string para poder obtener dummies\n",
    "df_cat[\"owner_card_type\"]=df_cat[\"owner_card_type\"].astype(str)\n",
    "df_cat[\"account_disponent_bin\"]=df_cat[\"account_disponent_bin\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dumm=pd.get_dummies(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dumm.dtypes\n",
    "#Al pasar a dummies las variables, hemos incrementado en 8 el número total de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_num, df_cat_dumm], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a generar un primer modelo benchmark y vamos a ver si podemos obtener una simplificación de los datos con PCA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Antes de probar con modelos vamos a ver si reduciendo dimensionalidad conseguimos una primera intuición.\n",
    "\n",
    "Cuando pasemos a generar modelos, estos han de predecir si una cuenta (account) contrata préstamo (loan=1) o no (loan=0). Es la variable \"account_loan_bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df_original[\"account_loan_bin\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit_transform(X)\n",
    "plt.figure(dpi=120)\n",
    "plt.scatter(pca[y.values==0,0], pca[y.values==0,1], alpha=0.5, label='NO', s=2, color='navy')\n",
    "plt.scatter(pca[y.values==1,0], pca[y.values==1,1], alpha=0.5, label='YES', s=2, color='darkorange')\n",
    "plt.legend()\n",
    "plt.title('Producto préstamo')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Del gráfico anterior no consigo sacar nada en claro\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X)\n",
    "print(pca2.components_)\n",
    "print(pca2.explained_variance_ratio_)\n",
    "#De los componentes de momento tampoco sacamos ninguna conclusión. Las variables están en escalas muy distintas y por eso \n",
    "#el PCA genera resultados tan \"positivos\" en cuanto a explicabilidad de las 2 primeras componentes principales (74%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empezamos con modelos sencillos. Estos modelos han de predecir si una cuenta (account) contrata préstamo (loan=1) o no (loan=0)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos conjuntos de train y de test. Para el test usamos el 20% de las observaciones\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos una Regresión logística\n",
    "clf_LR=LogisticRegression(random_state=0) #vamos a incluir Random State en todos los modelos para poder reproducirlos\n",
    "clf_LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una función para poder evaluar el modelo, ver si genera overfitting, underfitting y tener detallada la matriz de\n",
    "#confusión de los modelos que generemos\n",
    "def eval_modelo (clf,X_train,y_train, X_test,y_test):\n",
    "    print(\"Datos de train:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_train,clf.predict(X_train))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    tn, fp, fn, tp=confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "    print(\"tn:\",tn,\" fp:\",fp,\" fn:\",fn,\" tp:\",tp)\n",
    "    print(\"Datos de test:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_test,clf.predict(X_test))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    tn_t, fp_t, fn_t, tp_t=confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "    print(\"tn:\",tn_t,\" fp:\",fp_t,\" fn:\",fn_t,\" tp:\",tp_t)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelo(clf_LR,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Probamos con un árbol de decisión\n",
    "clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelo(clf_tree,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados de estos modelos tan sencillos están siendo extraordinarios. Vamos a investigar las razones.\n",
    "Además como las clases están desbalanceadas vamos a ir comparando el efecto de incluir oversampling o no. \n",
    "Vamos a profundizar con Decission Trees ya que tiene menores requerimientos teóricos para las features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las clases a predecir (si la cuenta tiene prestamo=1 ó no tiene =0) están desbalanceadas\n",
    "y2=pd.DataFrame(y)\n",
    "sns.countplot(x=\"account_loan_bin\",data=y2, palette='hls')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos el porcentaje que representa cada clase:\n",
    "print(\"Las cuentas CON préstamo son el\", \"%.2f\" % (y2['account_loan_bin'].value_counts()[0]/len(y2['account_loan_bin'])*100) ,\"%\")\n",
    "print(\"Las cuentas SIN préstamo son el\", \"%.2f\" % (y2['account_loan_bin'].value_counts()[1]/len(y2['account_loan_bin'])*100) ,\"%\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Al estar las clases desbalanceadas hay que ir con cuidado porque un modelo que prediga siempre NO tendría un accuracy\n",
    "de casi el 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a querer dibujar Decision Trees. Importamos los paquetes necesarios para dibujarlos\n",
    "from io import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para dibujar un árbol\n",
    "def dibu_arb(tree):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(tree, out_file=dot_data,filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    return(Image(graph.create_png()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[36]\n",
    "#Parece que la variable \"Num_Sym_LoanPayment\" contiene toda la información de \"account_loan_bin\", aunque se han extraido \n",
    "#de ficheros distintos. Pero por el nombre se puede intuir que es así. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree.feature_importances_>0.10] #Vamos a ver las variables más importantes para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[df_original['Num_Sym_LoanPayment']>0]['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Efectivamente las cuentas que tienen 'Num_Sym_LoanPayment'>0 se corresponden con todas las cuentas que han contratado préstamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link interesante para ver como se realiza el cálculo de \"feature_importances\"_\n",
    "#https://medium.com/@srnghn/the-mathematics-of-decision-trees-random-forest-and-feature-importance-in-scikit-learn-and-spark-f2861df67e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c glemaitre imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTENC\n",
    "#Hemos tomado SMOTENC y no SMOTE para poder aplicar el algoritmo a variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver las columnas que vamos a denominar como categóricas cuando apliquemos SMOTE\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "smo=SMOTENC(categorical_features=range(46,59),random_state=0)#Las variables categóricas van a ser de la 46 a la 59\n",
    "os_X,os_y=smo.fit_sample(X_train, y_train)\n",
    "columns = X_train.columns\n",
    "os_X = pd.DataFrame(data=os_X,columns=columns)\n",
    "os_y= pd.DataFrame(data=os_y,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Chequeamos que SMOTENC funciona como esperábamos\n",
    "\n",
    "print(\"length of oversampled data is \",len(os_X))\n",
    "print(\"Number of loans=0 in oversampled data\",len(os_y[os_y['account_loan_bin']==0]))\n",
    "print(\"Number of loans=1\",len(os_y[os_y['account_loan_bin']==1]))\n",
    "print(\"Proportion of loans=0 is \",len(os_y[os_y['account_loan_bin']==0])/len(os_X))\n",
    "print(\"Proportion of loans=1 is \",len(os_y[os_y['account_loan_bin']==1])/len(os_X))\n",
    "\n",
    "os_bin=os_X[['account_disponent_bin_0','account_disponent_bin_1',\n",
    "       'frequency_After_trans', 'frequency_Monthly', 'frequency_Weekly',\n",
    "       'sex_owner_F', 'sex_owner_M', 'owner_card_type_0', 'owner_card_type_1',\n",
    "       'owner_card_type_2', 'owner_card_type_3', 'sex_disponent_F',\n",
    "       'sex_disponent_M']]\n",
    "\n",
    "print(\"unique de variables categóricas\",unique(os_bin))\n",
    "print(\"unique de variable y\",unique(os_y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_os=os_clf_tree.fit(os_X,os_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eval_modelo(clf_tree_os,os_X,os_y, X_test, y_test)\n",
    "#Obtenemos los mismos resultados con y sin SMOTE. Lógicamente porque estamos suponiendo que la variable \n",
    "#'Num_Sym_LoanPayment' contiene la información de si la cuenta tiene un préstamo o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vemos que tener un préstamo correlaciona de forma muy significativa con las variables:Ord_Loan_Payment,Num_Sym_LoanPayment y \n",
    "#Ord_Loan_Payment_amount\n",
    "df_original.corr()[\"account_loan_bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos las correlaciones de las variables anteriores\n",
    "print(np.corrcoef(df_original[\"account_loan_bin\"],df_original[\"Ord_Loan_Payment\"]))\n",
    "print(np.corrcoef(df_original[\"account_loan_bin\"],df_original[\"Ord_Loan_Payment_amount\"]))\n",
    "print(np.corrcoef(df_original[\"account_loan_bin\"],df_original[\"Num_Sym_LoanPayment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a ver qué resultados obtenemos con los modelos eliminando la variable 'Num_Sym_LoanPayment' (la que anteriormente había\n",
    "#salido como más relevante). Generamos un nuevo DataFrame\n",
    "X1=X.drop(['Num_Sym_LoanPayment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_treeX1=X1_clf_tree.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Aplicamos oversampling\n",
    "smo=SMOTENC(categorical_features=range(45,58),random_state=0)# Modificamos rango porque hemos eliminado una variable\n",
    "os_X1,os_y1=smo.fit_sample(X1_train, y1_train)\n",
    "columns = X1_train.columns\n",
    "os_X1 = pd.DataFrame(data=os_X1,columns=columns)\n",
    "os_y1= pd.DataFrame(data=os_y1,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Chequeamos que SMOTENC funciona como esperábamos\n",
    "\n",
    "print(\"length of oversampled data is \",len(os_X1))\n",
    "print(\"Number of loans=0 in oversampled data\",len(os_y1[os_y1['account_loan_bin']==0]))\n",
    "print(\"Number of loans=1\",len(os_y1[os_y1['account_loan_bin']==1]))\n",
    "print(\"Proportion of loans=0 is \",len(os_y1[os_y1['account_loan_bin']==0])/len(os_X1))\n",
    "print(\"Proportion of loans=1 is \",len(os_y1[os_y1['account_loan_bin']==1])/len(os_X1))\n",
    "\n",
    "os_bin=os_X1[['account_disponent_bin_0','account_disponent_bin_1',\n",
    "       'frequency_After_trans', 'frequency_Monthly', 'frequency_Weekly',\n",
    "       'sex_owner_F', 'sex_owner_M', 'owner_card_type_0', 'owner_card_type_1',\n",
    "       'owner_card_type_2', 'owner_card_type_3', 'sex_disponent_F',\n",
    "       'sex_disponent_M']]\n",
    "print(\"unique de variables categóricas\",unique(os_bin))\n",
    "print(\"unique de variable y\",unique(os_y1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que el oversampling funciona bien, no lo vamos a chequear las próximas ocasiones"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "osX1_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_osX1=osX1_clf_tree.fit(os_X1,os_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los modelos\n",
    "print(\"Sin Oversampling\")\n",
    "eval_modelo(clf_treeX1,X1_train,y1_train, X1_test, y1_test)\n",
    "#print(\"Con Oversampling\")\n",
    "#eval_modelo(clf_tree_osX1,os_X1,os_y1, X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_treeX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dibu_arb(clf_tree_osX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.columns[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1.columns[clf_tree_osX1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.columns[clf_treeX1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[df_original['Ord_Loan_Payment_amount']>0]['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Las cuentas que tienen 'Ord_Loan_Payment_amount'>0 son mayoritariamente las cuentas que han contratado préstamo (y 35 cuentas adicionales) por lo tanto parece que 'Ord_Loan_Payment_amount' contiene la información de la variable que deseamos predecir. Generamos un nuevo Data Frame X2, a partir de X1 (al que ya habíamos eliminado 1 variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X1.drop(['Ord_Loan_Payment_amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el modelo SIN oversampling\n",
    "X2_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_treeX2=X2_clf_tree.fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Aplicamos oversampling\n",
    "smo=SMOTENC(categorical_features=range(44,57),random_state=0)# Modificamos rango porque hemos eliminado una nueva variable\n",
    "os_X2,os_y2=smo.fit_sample(X2_train, y2_train)\n",
    "columns = X2_train.columns\n",
    "os_X2 = pd.DataFrame(data=os_X2,columns=columns)\n",
    "os_y2= pd.DataFrame(data=os_y2,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Generamos el árbol con el DataFrame al hemos aplicado oversampling\n",
    "osX2_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_osX2=osX2_clf_tree.fit(os_X2,os_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los modelos\n",
    "print(\"Sin Oversampling\")\n",
    "eval_modelo(clf_treeX2,X2_train,y2_train, X2_test, y2_test)\n",
    "#print(\"Con Oversampling\")\n",
    "#eval_modelo(clf_tree_osX2,os_X2,os_y2, X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_treeX2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dibu_arb(clf_tree_osX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train.columns[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.columns[clf_treeX2.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X2.columns[clf_tree_osX2.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[df_original['Ord_Loan_Payment']>0]['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Como en el caso de 'Ord_Loan_Payment_amount' las cuentas que tienen 'Ord_Loan_Payment'>0 son mayoritariamente las cuentas que han contratado préstamo (y 35 cuentas adicionales) por lo tanto parece que 'Ord_Loan_Payment' contiene la información de la variable que deseamos predecir. Generamos un nuevo Data Frame X3, a partir de X2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el conjunto X3, a partir de X2, eliminando la variable 'Ord_Loan_Payment'\n",
    "X3=X2.drop(['Ord_Loan_Payment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el modelo SIN oversampling\n",
    "X3_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_treeX3=X3_clf_tree.fit(X3_train,y3_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Aplicamos oversampling\n",
    "smo=SMOTENC(categorical_features=range(43,56),random_state=0)# Modificamos rango porque hemos eliminado una nueva variable\n",
    "os_X3,os_y3=smo.fit_sample(X3_train, y3_train)\n",
    "columns = X3_train.columns\n",
    "os_X3 = pd.DataFrame(data=os_X3,columns=columns)\n",
    "os_y3= pd.DataFrame(data=os_y3,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Generamos el modelo CON oversampling\n",
    "osX3_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_osX3=osX3_clf_tree.fit(os_X3,os_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los modelos\n",
    "print(\"Sin Oversampling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "#print(\"Con Oversampling\")\n",
    "#eval_modelo(clf_tree_osX3,os_X3,os_y3, X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Con Oversampling estoy \"forzando\" al modelo a generar más positivos  (tp y fp), y en este caso se ve perfectamente como\n",
    "con oversampling mejoro el recall (porque tengo más positivos), pero empeoro la precision porque no los estoy prediciendo\n",
    "correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_treeX3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dibu_arb(clf_tree_osX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X3_train.columns[19])#Número de un tipo especial de reintegros\n",
    "print(X3_train.columns[25])#Número de retiradas de efectivo en cash\n",
    "print(X3_train.columns[8])#Número de Órdenes de Leasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.columns[clf_treeX3.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X3.columns[clf_tree_osX3.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_treeX3.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(clf_treeX3.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_original.corr()[\"account_loan_bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[df_original['Num_Type_VYBER']>0]['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'Num_Type_VYBER'>0 ocurre en el 68% (463 de 682) de las cuentas que han contratado un préstamo y también en muchas cuentas que no han contratado préstamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[df_original['Ord_Leasing']>0]['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'Ord_Leasing'>0 es una variable que predice que no se ha contratado préstamo, pero lo hace para un número pequeño de observaciones (341 de 4.500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Después de eliminar las variables que más suenan a \"préstamo\", parece que las siguientes variables más relevantes no contienen la información  de la variable que queremos predecir."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Me quedo con el DataSet X3 no elimino la variable Num_Type_VYBER, ya que los resultados, aunque son peores que inicialmente, son ahora más razonables (no parece que exista una variable que contenga toda la información de \"y\"=\"account_loan_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considero que el oversampling no me está aportando nada y dejo de utilizarlo en el resto del Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajamos a continuación sobre las variables con las que nos hemos quedado"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a seguir con árboles ya que es un modelo sencillo y que podría aportar explicabilidad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a hacer scaling, aplicado a árboles no debería tener un gran impacto, pero vamos a testearlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a probar Robust Scaling, partiendo del DataFrame X3 (después de eliminar las variables que parece que contenían \n",
    "#la información de si una cuenta ha contratado préstamo o no lo ha contratado)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rbs = RobustScaler()\n",
    "columns = X3.columns\n",
    "rbs_scale = rbs.fit_transform(X3)\n",
    "X=pd.DataFrame(rbs_scale,columns=columns)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling (el modelo con el conjunto X3 es el mismo que generamos en el análisis\n",
    "#anterior de variables)\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Scaling\")\n",
    "eval_modelo(X_clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados con Robust Scaling no mejoran, así que vamos a probar con Standard Scaling aunque en un modelo de\n",
    "Decision Tree esta transformación acostumbrará a tener poco impacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "columns = X3.columns\n",
    "scl_scale = scl.fit_transform(X3)\n",
    "X=pd.DataFrame(scl_scale,columns=columns)\n",
    "X_scl_scale=X.copy\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree_=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling (el modelo con el conjunto X3 es el mismo que generamos en el análisis\n",
    "#anterior de variables)\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Scaling\")\n",
    "eval_modelo(clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a probar si con el scaling, cuando hacemos PCA podemos obtener una representación simple de los datos. \n",
    "#Sé que va a ser difícil obtener una representación tan sencilla del Data Frame pero lo probamos.\n",
    "pca = PCA(n_components=2).fit_transform(X)\n",
    "plt.figure(dpi=120)\n",
    "plt.scatter(pca[y.values==0,0], pca[y.values==0,1], alpha=0.5, label='NO', s=2, color='navy')\n",
    "plt.scatter(pca[y.values==1,0], pca[y.values==1,1], alpha=0.5, label='YES', s=2, color='darkorange')\n",
    "plt.legend()\n",
    "plt.title('Producto préstamo')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Del gráfico anterior no consigo sacar nada en claro, no es posible discriminar las cuentas que han contratado préstamo \n",
    "#de las que no lo han contratado\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X)\n",
    "print(pca2.components_)\n",
    "print(pca2.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De las componentes principales de momento tampoco sacamos ninguna conclusión, pero al haber escalado los datos ahora obtenemos un dato más razonable de variabilidad explicada (28% con 2 variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling tampoco ha funcionado mejor que sin scaling. Aplicamos scaling sólo a las variables numéricas\n",
    "print(X3.columns)\n",
    "print(X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos las variables numéricas de las que consideramos categóricas\n",
    "X3_cat=X3[['account_disponent_bin_0','account_disponent_bin_1',\n",
    "       'frequency_After_trans', 'frequency_Monthly', 'frequency_Weekly',\n",
    "       'sex_owner_F', 'sex_owner_M', 'owner_card_type_0', 'owner_card_type_1',\n",
    "       'owner_card_type_2', 'owner_card_type_3', 'sex_disponent_F',\n",
    "       'sex_disponent_M']]\n",
    "X3_num=X3[['Date_Account', 'birth_owner', 'birth_disponent', 'owner_card_date',\n",
    "       'Ord_Insurance', 'Ord_Insurance_amount', 'Ord_Household_Payment',\n",
    "       'Ord_Household_Payment_amount', 'Ord_Leasing', 'Ord_Empty',\n",
    "       'Ord_Empty_amount', 'num_inhabitants', 'municip < 499',\n",
    "       'municip 500-1999', 'municip 2000-9999', 'municip > 10000',\n",
    "       'num_cities', 'avg_salary', 'Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances',\n",
    "       'Num_Op_Collection', 'Num_Op_CashCredit', 'Num_Op_WithdrawalCash',\n",
    "       'Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal',\n",
    "       'Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative', 'Ord_Leasing_amount', 'ratio_urban_inhabitants',\n",
    "       'unemployment_rate_95', 'unemployment_rate_96', 'crimes_95_ratio',\n",
    "       'crimes_96_ratio', 'entrepreneurs_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos con el Robust Scaling\n",
    "columns = X3_num.columns\n",
    "X3_scale = rbs.fit_transform(X3_num)\n",
    "X3_scale=pd.DataFrame(X3_scale,columns=columns)\n",
    "X = pd.concat([X3_scale,X3_cat], axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree_=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Robust Scaling sólo en variables numéricas\")\n",
    "eval_modelo(clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En este caso, el robust scaling tampoco mejora los resultados que teníamos originalmente. Probamos otra alternativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos con min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X3_num.columns\n",
    "X3_scale = minmax.fit_transform(X3_num)\n",
    "X3_scale=pd.DataFrame(X3_scale,columns=columns)\n",
    "X = pd.concat([X3_scale,X3_cat], axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree_=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Scaling\")\n",
    "eval_modelo(clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Con scaling MinMax el modelo casi no genera predicciones positivas y el accuracy se obtiene por un modelo que básicamente\n",
    "predice en test y train que la cuenta no contrata préstamo y al estar las clases desbalanceadas obtenemos ese Acuraccy (85% aprox), pero muy mal Recall y Precision"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hasta el momento hemos visto que en el dataset que habíamos generado habían 3 variables que \"contenían\" la información de la variable que queríamos predecir y también hemos visto que, en el caso de Decision Trees, las técnicas de Oversampling y de Scaling tal y como las hemos aplicado no mejoran los modelos iniciales."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a trabajar a continuación sobre las features numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X3_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir del DataFrame X3 creamos un DataFrame que contenga el log natural de las variables numéricas\n",
    "cols = X3_num.columns\n",
    "X3_log=pd.DataFrame(X3_num,columns=columns)#También podríamos hacer un copy del DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el logaritmo de las variables que consideramos numéricas\n",
    "cols=X3_num.columns\n",
    "for col in cols:\n",
    "    X3_log[col]=X3_log[col]+1.1 #Para evitar negativos al aplicar el logaritmo añadimos 1.1 (las variables son >=0)\n",
    "    X3_log[col]=np.log(X3_log[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hemos disminuido la variabilidad de las features\n",
    "X3_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame a partir del DataFrame X3 (una vez eliminadas las 3 variables que contenían la información de la variable\n",
    "#a predecir), aplicando logaritmo a las variables que consideramos numéricas y dejando las categóricas igual.\n",
    "X_log= pd.concat([X3_log,X3_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Adicionalmente al DataFrame anterior, vamos a crear un nuevo DataFrame binarizando las variables que tienen el número de operaciones (pasan de tener el número de operaciones a decir si la cuenta ha realizado ese tipo de operativa o no) y eliminando las columnas que contienen el sufijo \"_amount\" (sólo queremos reflejar si se ha realizado un tipo de operativa o no se ha realizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_bin=['Ord_Insurance', 'Ord_Household_Payment','Ord_Leasing', 'Ord_Empty','Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances','Num_Op_Collection', 'Num_Op_CashCredit', \n",
    "       'Num_Op_WithdrawalCash','Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal','Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative']\n",
    "\n",
    "col_out=['Ord_Insurance_amount','Ord_Household_Payment_amount','Ord_Empty_amount', 'Ord_Leasing_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X3.columns\n",
    "X3_bin=pd.DataFrame(X3,columns=cols)\n",
    "X3_bin=X3_bin.drop(col_out, axis=1)#Eliminamos las columnas de amount\n",
    "X3_bin=X3_bin.drop(col_to_bin, axis=1)#Eliminamos las columnas a binarizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el dataset que queremos binarizar\n",
    "X3_to_bin=X3[['Ord_Insurance', 'Ord_Household_Payment','Ord_Leasing', 'Ord_Empty','Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances','Num_Op_Collection', 'Num_Op_CashCredit', \n",
    "       'Num_Op_WithdrawalCash','Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal','Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que para cada observación de cada variable asigna 1 si el valor>0 y 0 en otro caso (no tenemos valores negativos)\n",
    "def binario(x):\n",
    "    if x>0:\n",
    "        x=1\n",
    "    else:\n",
    "        x=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos la función anterior a las variables que deseamos binarizar \n",
    "for col in col_to_bin:\n",
    "    X3_to_bin[col]=X3_to_bin[col].apply(binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X3_to_bin=X3_to_bin.astype(str)\n",
    "X3_to_bin=pd.get_dummies(X3_to_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame a partir del DataFrame X3 (una vez eliminadas las 3 variables que contenían la información de la variable\n",
    "#dependiente), binarizando las variables que contaban el número de operaciones.\n",
    "X_bin= pd.concat([X3_bin,X3_to_bin], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con los nuevos DataFrames de features vamos a intentar encontrar el mejor Decision Tree y ver cuales son las variables más significativas para dicho modelo, que podrían servir para establecer un custome journey del cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los DataFrames con los que vamos a trabajar son:\n",
    "#X_orig: El Dataframe con el que habíamos trabajado antes eliminando 3 variables, también lo llamábamos X3.\n",
    "X=X3\n",
    "#X_log: Es el Dataframe X_orig pero haciendo el logaritmo natural a las variables numéricas\n",
    "#X_bin: Es el Dataframe X_orig pero binarizando las variables que contaban cuantas operaciones de cada tipo se habían realizado\n",
    "#en cada cuenta, ahora decimos si la cuenta tiene ese tipo de operativa o no, y eliminando las variables que cuantificaban los\n",
    "#importes de dicha operativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Inicialmente pensaba considerar como única métrica la precisión (quería que el modelo minimizase los falsos positivos,\n",
    "pero en vista de los resultados de los modelos anteriores, en los que el recall (el % de positivos que acierto) \n",
    "puede ser muy bajo voy a comenzar a monitorizar también el F1 Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incluimos la métrica del F1 Score en la evaluación de los modelos. Modificamos la función anterior de evaluación\n",
    "def eval_modelo_2 (clf,X_train,y_train, X_test,y_test):\n",
    "    print(\"Datos de train:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_train,clf.predict(X_train))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_train,clf.predict(X_train))*100, \"%\")\n",
    "    print(\"El F1 Score es\",f1_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    tn, fp, fn, tp=confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "    print(\"tn:\",tn,\" fp:\",fp,\" fn:\",fn,\" tp:\",tp)\n",
    "    print(\"Datos de test:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_test,clf.predict(X_test))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    print(\"El F1 Score es\",f1_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    tn_t, fp_t, fn_t, tp_t=confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "    print(\"tn:\",tn_t,\" fp:\",fp_t,\" fn:\",fn_t,\" tp:\",tp_t)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a definir la parrilla para realizar Randomized Grid Search\n",
    "\n",
    "# Máximo número de niveles en el árbol. Damos una distribución con mayor probabilidad en valores pequeños\n",
    "max_depth1 = [int(x) for x in np.linspace(2, 20, num = 10)]#\"Sobreponderamos\" árboles con poca profundidad\n",
    "max_depth2 =[int(x) for x in np.linspace(30, 100, num = 4)]\n",
    "max_depth=max_depth1 + max_depth2\n",
    "\n",
    "# Mínimo número de observaciones en cada hoja. Damos una distribución con mayor probabilidad en los valores más elevados\n",
    "min_samples_leaf_1 = [int(x) for x in np.linspace(5, 50, num = 4)]\n",
    "min_samples_leaf_2 = [int(x) for x in np.linspace(60, 100, num = 10)]\n",
    "min_samples_leaf=min_samples_leaf_1+min_samples_leaf_2\n",
    "\n",
    "# Hemos asignado mayor número de casos a los parámetros que podrían facilitar la explicabilidad del Decision Tree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la grid aleatoria\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(random_state=0)\n",
    "#Creamos una versión para optimizar la precision\n",
    "clf_tree_random_p= RandomizedSearchCV(random_state=0,estimator = clf_tree, param_distributions = random_grid, n_iter = 100, cv = 5,scoring=\"precision\")\n",
    "#Creamos una versión para optimizar el F1 Score\n",
    "clf_tree_random_f1= RandomizedSearchCV(random_state=0,estimator = clf_tree, param_distributions = random_grid, n_iter = 100, cv = 5,scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzamos por el DataFrame X (el X3 anterior)\n",
    "#Generamos conjuntos de train y el de test. Para el test usamos el 20% de las observaciones\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_tree_random_p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_p.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_p = clf_tree_random_p.best_estimator_\n",
    "#Otra alternativa podría ser, a partir de los parámetros obtenidos con RandomizedSearchCV entrenar el modelo con todo\n",
    "#el conjunto de train y tener así los datos de validación del Cross Validation también para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelo_2 (clf_tree_p,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parece que el modelo anterior produce overfitting, sobretodo en las métricas de Precision y Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_p.feature_importances_>0.10]\n",
    "#Las variables que obtenemos de este árbol que parece que produce overfitting son las que habíamos visto anteriormente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score\n",
    "\n",
    "clf_tree_random_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_f1.best_params_)\n",
    "\n",
    "clf_tree_f1 = clf_tree_random_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_tree_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atención: obtengo mejor precision en el modelo que optimiza F1 Score que en el que optimiza Precision. Dado que el coste  \n",
    "computacional es bajo, creo que va a ser mejor aplicar GridSearch CV en lugar de RandomizedGridSearchCV, para no obtener \n",
    "resultados incoherentes por estar utilizando Randomized GridSearch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comparando el modelo que optimizamos el F1 Score, respecto al que optimizamos la precision, creo que es mejor el que optimiza\n",
    "el F1 Score porque aunque la precision puede bajar un poco, el recall aumenta de forma más significativa. Esto lo consigue \n",
    "generando un mayor número de positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.columns[19])#Número de un tipo especial de reintegros\n",
    "print(X_train.columns[34])#Número de abonos de intereses de depósitos\n",
    "print(X_train.columns[36])#Importe de Órdenes de Leasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a ver si la manipulación de variables que habíamos realizado anteriormente puede mejorar el modelo\n",
    "#Comenzamos por el DataFrame X_log\n",
    "#Generamos conjuntos de train y de test. Para el test usamos el 20% de las observaciones\n",
    "X_log_train, X_log_test, y_log_train, y_log_test = train_test_split(X_log, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_random_p.fit(X_log_train, y_log_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_p.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_p = clf_tree_random_p.best_estimator_  \n",
    "\n",
    "eval_modelo_2(clf_tree_p,X_log_train, y_log_train,X_log_test, y_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_p.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizamos ahora el F1 Score\n",
    "clf_tree_random_f1.fit(X_log_train, y_log_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_f1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_f1 = clf_tree_random_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_tree_f1,X_log_train, y_log_train,X_log_test, y_log_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atención: Vuelvo a obtener mejor Precision en el modelo que optimiza F1 Score que en el que optimiza Precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log.columns[clf_tree_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A continuación seguimos con el DataFrame X_bin, en el que hemos binarizado las variables que contaban el número de veces que \n",
    "#se produce una operativa.\n",
    "#Generamos conjuntos de train y de test. Para el test usamos el 20% de las observaciones\n",
    "X_bin_train, X_bin_test, y_bin_train, y_bin_test = train_test_split(X_bin, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_random_p.fit(X_bin_train, y_bin_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_p.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_p = clf_tree_random_p.best_estimator_  \n",
    "\n",
    "eval_modelo_2(clf_tree_p,X_bin_train, y_bin_train,X_bin_test, y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin.columns[clf_tree_p.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizamos ahora el F1 Score\n",
    "clf_tree_random_f1.fit(X_bin_train, y_bin_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_f1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_f1 = clf_tree_random_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_tree_f1,X_bin_train, y_bin_train,X_bin_test, y_bin_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Con el DataFrame en el que binarizamos las variables, los resultados son claramente los peores obtenidos hasta el momento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atención: Con este último dataset hemos obtenido mejor Precision en el modelo que optimiza Precisión que en el que optimiza \n",
    "F1 Score (que es lo esperable), pero como en los casos anteriores no había sido así, y dado que el coste computacional es bajo, creo que va a ser mejor aplicar GridSearch CV en lugar de RandomizedGridSearchCV, para asegurar que los resultados incoherentes no vienen por el efecto Random de RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin.columns[clf_tree_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los DataFrames aplicando logaritmo y binarizando no mejoran el resultado del DataFrame original, se puede entender porque el\n",
    "modelo que estamos aplicando es un árbol en el caso del logaritmo y al binarizar estamos perdiendo información.\n",
    "\n",
    "También estamos viendo que consistentemente las variables que son más relevantes son:\n",
    "--Num_Type_VYBER\n",
    "--Ord_Leasing (en algunos modelos tal cual y en otros como Ord_Leasing_amount\n",
    "\n",
    "A continuación vamos a aplicar GridSearch con el conjunto de datos procedente de X3 (datos originales menos 3 variables)\n",
    "y vamos a ver que variables nos salen como más relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos la misma matriz de hiperparámetros\n",
    "grid=random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=StratifiedKFold(n_splits=5, random_state=0,shuffle=False)\n",
    "#Probamos con esta técnica por si el hecho que la Precision salga mejor optimizando F1 Score que optimizando Precision es por\n",
    "#algún factor aleatorio al aplicar Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los modelos para hacer la búsqueda de hiperparámetros \n",
    "clf_tree = DecisionTreeClassifier(random_state=0)\n",
    "#Creamos una versión para optimizar la precision\n",
    "clf_tree_gridsearch_p= GridSearchCV(estimator = clf_tree, param_grid = grid, cv=k, scoring=\"precision\")\n",
    "#Creamos una versión para optimizar el F1 Score\n",
    "clf_tree_gridsearch_f1= GridSearchCV(estimator = clf_tree, param_grid = grid, cv=k, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre Precision\n",
    "\n",
    "clf_tree_gridsearch_p.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_gridsearch_p.best_params_)\n",
    "\n",
    "clf_tree_gs_p = clf_tree_gridsearch_p.best_estimator_  \n",
    "\n",
    "\n",
    "eval_modelo_2 (clf_tree_gs_p,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos las features de mayor relevancia en el modelo\n",
    "X.columns[clf_tree_gs_p.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score\n",
    "\n",
    "clf_tree_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_tree_gs_f1 = clf_tree_gridsearch_f1.best_estimator_\n",
    "\n",
    "\n",
    "eval_modelo_2 (clf_tree_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "¿Cómo puede ser que obtenga un mejor resultado en Precision cuando optimizo F1 que cuando optimizo precision?. ¿Puede que no esté aplicando correctamente algún parámetro?.\n",
    "\n",
    "Un modelo que siempre diga que una cuenta no contrata préstamo no sirve de nada porque no va a responder a nuestra pregunta de negocio, pero es destacable que ese modelo tendría mejor Accuracy que el modelo que hemos obtenido hasta el momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la relevancia de las features en el modelo\n",
    "clf_tree_gs_f1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_gs_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De la búsqueda Gridsearch anterior, concluimos que la optimización del F1 Score se va a obtener con un modelo con un bajo max_depth y un bajo min_samples_leaf . Volvemos a hacer GridSearchCV con hiperparámetros más acotados a valores bajos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grid={'max_depth': [1,2,3,4,5],\n",
    " 'min_samples_leaf': [2,3,4,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los modelos para hacer la búsqueda de hiperparámetros \n",
    "clf_tree = DecisionTreeClassifier(random_state=0)\n",
    "#Creamos una versión para optimizar la precision\n",
    "clf_tree_gridsearch_p= GridSearchCV(estimator = clf_tree, param_grid = new_grid, cv=k, scoring=\"precision\")\n",
    "#Creamos una versión para optimizar el F1 Score\n",
    "clf_tree_gridsearch_f1= GridSearchCV(estimator = clf_tree, param_grid = new_grid, cv=k, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre Precision\n",
    "\n",
    "clf_tree_gridsearch_p.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_gridsearch_p.best_params_)\n",
    "\n",
    "clf_tree_gs_p = clf_tree_gridsearch_p.best_estimator_  \n",
    "\n",
    "\n",
    "eval_modelo_2 (clf_tree_gs_p,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score\n",
    "\n",
    "clf_tree_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_tree_gs_f1 = clf_tree_gridsearch_f1.best_estimator_\n",
    "\n",
    "\n",
    "eval_modelo_2 (clf_tree_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parece que este es el mejor modelo que podemos obtener con Decision Trees. La Precision y el Recall están lejos de lo que consideraríamos un buen modelo ya que aunque solo soy capaz de predecir el 66% aproximadamente de las cuentas que han contratado préstamo, en cuanto a Precision consigo un valor inferior al 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_gs_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_gs_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizamos a continuación la interpretabilidad de los resultados obtenidos "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El árbol obtenido anteriomente es sencillo de interpretar, pero los árboles no tiene porque serlo siempre. A pesar de lo anterior vamos a profundizar en técnicas que permitan interpretar los resultados obtenidos."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para ver el impacto de las variables en la probabilidad de que una cuenta tenga un préstamo vamos a aplicar Partial Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdpbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ruta interesante para entender el Partial Dependece Plot\n",
    "https://christophm.github.io/interpretable-ml-book/pdp.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "También vamos a utilizar Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge shap "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Páginas interesantes para interpretar Shap Values\n",
    "https://github.com/slundberg/shap\n",
    "http://www.f1-predictor.com/model-interpretability-with-shap/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzamos el análisis de los SHAP values\n",
    "explainer = shap.TreeExplainer(clf_tree_gs_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos los SHAP values para el train\n",
    "shap_values_train = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos tambien los SHAP values para el test\n",
    "shap_values_test = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de variable Num_Type_VYBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_train, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para el caso de Num_Type_VYBER, vemos que el tener este tipo de operativa incrementa la posibilidad de haber contratado\n",
    "un préstamo hasta en un 40% (aproximadamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la distribución de la variable y en cuantas observaciones tiene efecto esta feature\n",
    "plt.hist(X['Num_Type_VYBER'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En la distribución de la variable 'Num_Type_VYBER', vemos que la frecuencia disminuye a medida que se incrementa el número de 'Num_Type_VYBER', indicando que el Partial Dependence Plot puede ser menos relevante a medida que se incrementa 'Num_Type_VYBER' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Num_Type_VYBER']>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Para asegurar la consistencia del análisis de Partial Dependence vamos a analizar la correlación de esta variable con el resto\n",
    "#de variables\n",
    "X.corr()[\"Num_Type_VYBER\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que \"Num_Type_VYBER\" tiene correlación que podría ser elevada con \"Num_Sym_Null\" y \"Num_Op_WithdrawalCash\", entorno\n",
    "a un 0,50.\n",
    "\n",
    "Vamos a ver que conclusiones podemos obtener con SHAP Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de train. En los desplegables de X e Y hay que seleccionar la variable Num_Type_VYBER (X) y\n",
    "# Num_Type_VYBER effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_train[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de test. En los desplegables de X e Y hay que seleccionar la variable Num_Type_VYBER (X) y\n",
    "# Num_Type_VYBER effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_test[1], X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que en el caso de SHAP values, la relación entre el número de operaciones de tipo Vyber y su contribución a la probabilidad de contratar un préstamo no es monotónica, ni constante. En general, para valores bajos de Num_Type_VYBER (pero superiores a 0), esta característica incrementa la posibilidad de haber contratado préstamo, pero para valores elevados de esta variable hay parece contribuir negativamente. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El scatter plot que se muestra a continuación también muestra que las cuentas con mayor operativa de tipo Vyber, tienden a no haber contratado préstamos. Esta casuísitica debería analizarse en mayor profundidad, revisando dichas cuentas y viendo por ejemplo si contratan otro tipo de productos de crédito que no estén entrando en el fichero de loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X.Num_Type_VYBER, y)\n",
    "plt.xlabel(\"Num_Type_VYBER\")\n",
    "plt.ylabel(\"account_loan_bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de variable Ord_Leasing_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Ord_Leasing' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_train, model_features=X.columns, feature='Ord_Leasing_amount')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Leasing_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_test, model_features=X.columns, feature='Ord_Leasing_amount')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Leasing_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de Ord_Leasing, vemos que el tener este tipo de operativa disminuye la probabilidad de haber contratado un préstamo en un 10% aproximandamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la distribución de la variable y en cuantas observaciones tiene efecto esta feature\n",
    "plt.hist(X['Ord_Leasing_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Ord_Leasing_amount']>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para evaluar la consistencia del análisis de Partial Dependence vamos a analizar la correlación de esta variable con el resto\n",
    "#de variables\n",
    "X.corr()[\"Ord_Leasing_amount\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que \"Ord_Leasing_amount\" tiene correlación elevada con \"Ord_Leasing\" (0,88) ya que ambas son distintas de cero en los mismos casos y a medida que una de ellas crece la otra también debe hacerlo. Y la siguiente mayor correlación es con \"Num_Type_VYBER\" de 0,30.\n",
    "\n",
    "A continuación, vamos a ver que conclusiones podemos obtener con SHAP Values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Num_Type_VYBER, X.Ord_Leasing_amount)\n",
    "plt.xlabel(\"Num_Type_VYBER\")\n",
    "plt.ylabel(\"Ord_Leasing_amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de train. En los desplegables de X e Y hay que seleccionar la variable Ord_Leasing (X) y\n",
    "#Ord_Leasing effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_train[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de test. En los desplegables de X e Y hay que seleccionar la variable Ord_Leasing (X) y\n",
    "#Ord_Leasing effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_test[1], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Ord_Leasing_amount, y)\n",
    "plt.xlabel(\"Ord_Leasing_amount\")\n",
    "plt.ylabel(\"account_loan_bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Ord_Leasing, y)\n",
    "plt.xlabel(\"Ord_Leasing\")\n",
    "plt.ylabel(\"account_loan_bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que tener Ord_Leasing_amoun<500, incrementa ligeramente la probabilidad de haber contratado un préstamo, mientras que Ord_Leasing_amount>500 disminuye dicha probabilidad. Habíamos visto antes que las cuentas que tienen órdenes de Leasing no habían contratado préstamo.\n",
    "\n",
    "Es también llamativo que ninguna de las cuentas que ha contratado un préstamo ha tenido activo las órdenes/domiciliaciones de Leasing (scatter plot). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Calculadora\" de SHAP values para las observaciones de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para cada observación i podemos ver el impacto de las distintas features en su probabilidad de haber contratado un préstamo\n",
    "i=52\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_test[1][i,:], feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para cada observación i podemos ver el valor de las variables que hemos seleccionado (las más significativas del modelo)\n",
    "X_test.iloc[i][['Num_Type_VYBER','Ord_Leasing_amount']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Esta calculadora podría hacerse para los valores de test (o para cualquier otro conjunto), simplemente cambiando en las celdas anteriores test por el conjunto que queramos analizar y calculando los SHAP values para dicho conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A continuación  vamos a ver qué resultados obtendríamos con Random Forest (un modelo más potente también basado en árboles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vamos a dejar el código en formato texto, por el tiempo de ejecución. \n",
    "grid_RF = {'max_depth':[3,5,10,25,50,75,100], \n",
    "        'n_estimators':[50,100,250,500,750,1000]}\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_RF= RandomForestClassifier(min_samples_leaf=5,random_state=0)\n",
    "\n",
    "#Probamos directamente con la optimización de F1 Score\n",
    "clf_RF_gridsearch_f1= GridSearchCV(estimator = clf_RF, param_grid = grid_RF, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_RF_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_RF_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_RF_gs_f1 = clf_RF_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vamos a dejar el código en formato texto, por el tiempo de ejecución. \n",
    "grid_RF = {'max_depth': [20,30,40,50,60,70], \n",
    "        'n_estimators':[150,200,250,300,350]}\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_RF= RandomForestClassifier(min_samples_leaf=5,random_state=0)\n",
    "\n",
    "#Probamos directamente con la optimización de F1 Score\n",
    "clf_RF_gridsearch_f1= GridSearchCV(estimator = clf_RF, param_grid = grid_RF, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_RF_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_RF_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_RF_gs_f1 = clf_RF_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como en el caso anterior vamos a dejar el código en formato texto, por el tiempo de ejecución. Vamos a probar con 200 árboles/estimadores y vamos a optimizar los parámetros:'max_depth' y'min_samples_leaf'\n",
    "grid_RF = {'max_depth': [10,15,20,25,30], \n",
    "        'n_estimators':[60,70,80,90]}\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_RF= RandomForestClassifier(min_samples_leaf=5,random_state=0)\n",
    "\n",
    "#Probamos directamente con la optimización de F1 Score\n",
    "clf_RF_gridsearch_f1= GridSearchCV(estimator = clf_RF, param_grid = grid_RF, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_RF_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_RF_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_RF_gs_f1 = clf_RF_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En el caso de optimizar el F1 Scores con número de estimadores=200, las features más relevantes siguen siendo \n",
    "#las que habíamos visto anteriormente:\n",
    "X.columns[clf_RF_gs_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De forma contraintuitiva, los resultados del Random Forest no están mejorando los metricas obtenidas por un sólo Decision Tree, pero la información relativa a las variables de mayor relevancia para las cuentas que contratan préstamos coinciden con las obtenidas por un sólo Decision Tree, que hemos analizado anteriormente.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A continuación  vamos a ver qué resultados obtendríamos con un modelo más potente, tambien basado en árboles, como Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para garantizar la replicabilidad del análisis\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como este código tarda bastante en ejecutarse lo ponemos como texto y utilizaremos sus resultados\n",
    "\n",
    "#Vamos a hacer un RandomSearch para ver cuales son las variables más significativas de un modelo que a priori va a mejorar\n",
    "#bastante los modelos que hemos obtenido hasta ahora con Random Forest y Decision Trees:\n",
    "grid_GBC = {'max_depth': [3,10,50,100,200,500], \n",
    "        'n_estimators':[50,100,200,500,1000,1500,2000],'learning_rate': [0.05,0.1,0.5,0.75,0.99]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_GBC_randomsearch = GradientBoostingClassifier(min_samples_leaf=5,random_state=0)\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_GBC_randomsearch_f1= RandomizedSearchCV(random_state=0,n_jobs=-1,estimator =clf_GBC_randomsearch, param_distributions =grid_GBC, n_iter = 200, cv = 5,scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_GBC_randomsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_GBC_randomsearch_f1.best_params_)\n",
    "\n",
    "clf_GBC_rs_f1 = clf_GBC_randomsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_GBC_rs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Muy fácilmente obtenemos modelos que aprenden el 100% de los datos de Train, aunque en este caso, claramente tiene overfitting\n",
    "clf_GBC = GradientBoostingClassifier(max_depth=10,random_state=0)\n",
    "clf_GBC.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_GBC,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_GBC.feature_importances_>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muy fácilmente obtenemos modelos que aprenden el 100% de los datos de Train (sólo variando un parámetro)\n",
    "clf_GBC = GradientBoostingClassifier(n_estimators=1200,random_state=0)\n",
    "clf_GBC.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_GBC,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_GBC.feature_importances_>0.1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En comparación con el modelo anterior hemos conseguido ahora un modelo que genera más positivos y además los acierta, mejorando de esta forma el recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como este código tarda bastante en ejecutarse lo ponemos como texto y utilizaremos sus resultados\n",
    "\n",
    "#Vamos a hacer un RandomSearch para ver cuales son las variables más significativas de un modelo que a priori va a mejorar\n",
    "#bastante los modelos que hemos obtenido hasta ahora con Random Forest y Decision Trees:\n",
    "grid_GBC = {'max_depth': [3,4,5,7],'min_samples_leaf': [5,10,15,20], \n",
    "        'n_estimators':[100,500,1000,2000],'learning_rate': [0.05,0.1,0.2,0.5]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_GBC_randomsearch = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_GBC_randomsearch_f1= RandomizedSearchCV(random_state=0,n_jobs=-1,estimator =clf_GBC_randomsearch, param_distributions =grid_GBC, n_iter = 70, cv = 5,scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_GBC_randomsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_GBC_randomsearch_f1.best_params_)\n",
    "\n",
    "clf_GBC_rs_f1 = clf_GBC_randomsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_GBC_rs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parece que el Randomized Search nos lleva a modelos sencillos y con learning rate elevado\n",
    "\n",
    "#Vamos a hacer un GridSearch para ver cuales son las variables más significativas de un modelo que a priori va a mejorar\n",
    "#bastante los modelos que hemos obtenido hasta ahora con Random Forest y Decision Trees:\n",
    "grid_GBC = {'max_depth': [2,3,4], \n",
    "        'n_estimators':[1,10,50,100],'learning_rate': [0.5,0.75,0.99]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_GBC_gridsearch = GradientBoostingClassifier(random_state=0, min_samples_leaf=5)\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_GBC_gridsearch_f1= GridSearchCV(estimator = clf_GBC_gridsearch, param_grid = grid_GBC, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_GBC_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_GBC_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_GBC_gs_f1 = clf_GBC_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_GBC_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parece que el Randomized Search nos sigue llevando a modelos sencillos y con learning rate elevado\n",
    "\n",
    "#Vamos a hacer un GridSearch para ver cuales son las variables más significativas de un modelo que a priori va a mejorar\n",
    "#bastante los modelos que hemos obtenido hasta ahora con Random Forest y Decision Trees:\n",
    "grid_GBC = {'max_depth': [2,3,4], \n",
    "        'n_estimators':[1,2,3,5],'learning_rate': [0.9,0.95,0.99,1]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_GBC_gridsearch = GradientBoostingClassifier(random_state=0, min_samples_leaf=5)\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_GBC_gridsearch_f1= GridSearchCV(estimator = clf_GBC_gridsearch, param_grid = grid_GBC, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_GBC_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_GBC_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_GBC_gs_f1 = clf_GBC_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_GBC_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Este modelo supera al obtenido con Decision Trees.\n",
    "\n",
    "Matriz confusion Decision Trees= tn: 739  fp: 18  fn: 40  tp: 103\n",
    "\n",
    "Matriz confusion GBC=  tn: 653  fp: 104  fn: 46  tp: 97\n",
    "\n",
    "Vemos que hay una mejora relevante en todas las magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos cuales son las variables más significativas para este modelo \n",
    "X.columns[clf_GBC_gs_f1.feature_importances_>0.1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Las variables más significativas son similares a las de los modelos anteriores. Vamos a ver que explicabilidad podemos encontrar con SHAPE Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siguiendo las indicaciones de la página https://github.com/slundberg/shap, vemos que no hay una implementación rápida \n",
    "#para los modelos de Gradient Boosting Classifier y debemos utilizar la implementación genérica\n",
    "explainer = shap.KernelExplainer(clf_GBC_gs_f1.predict_proba,X_train, link=\"logit\")\n",
    "shap_values = explainer.shap_values(X_test,nsamples=2)\n",
    "#Incluimos un nsamples bajo para ver que el código se puede ejecutar pero no lo ejecutamos con nsamples alto porque tarda mucho\n",
    "#en ejecutarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con pocas samples, SHAPE values no funciona muy bien (no muestra valores), pero a continuación muestro una \"calculadora\" \n",
    "#para poder analizar el efecto de cada variable en una observación dada\n",
    "i=10\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][52,:], X_test.iloc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_train, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Ord_Leasing' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_train, model_features=X.columns, feature='Ord_Leasing')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Leasing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Ord_Leasing' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Ord_Leasing')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Leasing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a trabajar sobre las features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X3_num.columns\n",
    "X3_scale = minmax.fit_transform(X3_num)\n",
    "X3_scale=pd.DataFrame(X3_scale,columns=columns)\n",
    "X_scale_minmax = pd.concat([X3_scale,X3_cat], axis = 1)\n",
    "X_scale_minmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale_minmax_train, X_scale_minmax_test, y_train, y_test = train_test_split(X_scale_minmax, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos con el Robust Scaling\n",
    "columns = X3_num.columns\n",
    "X3_scale = rbs.fit_transform(X3_num)\n",
    "X3_scale=pd.DataFrame(X3_scale,columns=columns)\n",
    "X_scale_rbs = pd.concat([X3_scale,X3_cat], axis = 1)\n",
    "X_scale_rbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale_rbs_train, X_scale_rbs_test, y_train, y_test = train_test_split(X_scale_rbs, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a probar con Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con kernel LINEAR\n",
    "grid_SVM = {'C': [0.1,1,5,10], \n",
    "        'gamma':['scale','auto'],'max_iter': [1000,10000,100000]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_SVM_gridsearch = SVC(random_state=0, kernel=\"linear\")\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_SVM_gridsearch_f1= GridSearchCV(estimator = clf_SVM_gridsearch, param_grid = grid_SVM, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_SVM_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_SVM_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_SVM_gs_f1 = clf_SVM_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_SVM_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos si un mayor número de iteraciones mejora los resultados\n",
    "clf_SVM = SVC(kernel=\"linear\",C=1,gamma='scale',max_iter=1000000, random_state=0)\n",
    "clf_SVM.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos si un mayor número de iteraciones mejora los resultados\n",
    "clf_SVM = SVC(kernel=\"linear\",C=1,gamma='scale',max_iter=10000000, random_state=0)\n",
    "clf_SVM.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_train,y_train, X_test,y_test)\n",
    "#Este modelo tiende a no generar positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVM = SVC(kernel=\"linear\",C=10,gamma='scale',max_iter=1000000, random_state=0)\n",
    "clf_SVM.fit(X_scale_rbs_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_scale_rbs_train,y_train, X_scale_rbs_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVM = SVC(kernel=\"linear\",C=10,gamma='scale',max_iter=1000000, random_state=0)\n",
    "clf_SVM.fit(X_scale_minmax_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_scale_minmax_train,y_train, X_scale_minmax_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVM = SVC(kernel=\"linear\",C=10,gamma='scale',max_iter=1000000, random_state=0)\n",
    "clf_SVM.fit(X_log_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_log_train,y_train, X_log_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con kernel RBF\n",
    "grid_SVM = {'C': [0.1,1,5,10], \n",
    "        'gamma':['scale','auto'],'max_iter': [1000,10000,100000]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_SVM_gridsearch = SVC(random_state=0, kernel=\"rbf\")\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_SVM_gridsearch_f1= GridSearchCV(estimator = clf_SVM_gridsearch, param_grid = grid_SVM, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_SVM_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_SVM_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_SVM_gs_f1 = clf_SVM_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_SVM_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con kernel RBF\n",
    "grid_SVM = {'C': [8,10,15,25,50],'max_iter': [500,1000,2000,5000]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_SVM_gridsearch = SVC(random_state=0, kernel=\"rbf\", gamma='scale')\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_SVM_gridsearch_f1= GridSearchCV(estimator = clf_SVM_gridsearch, param_grid = grid_SVM, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_SVM_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_SVM_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_SVM_gs_f1 = clf_SVM_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_SVM_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con kernel RBF\n",
    "grid_SVM = {'C': [8,10,15,25,50],'max_iter': [500,1000,2000,5000]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_SVM_gridsearch = SVC(random_state=0, kernel=\"rbf\", gamma='scale')\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_SVM_gridsearch_f1= GridSearchCV(estimator = clf_SVM_gridsearch, param_grid = grid_SVM, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_SVM_gridsearch_f1.fit(X_log_train, y_log_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_SVM_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_SVM_gs_f1 = clf_SVM_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_SVM_gs_f1,X_log_train,y_log_train, X_log_test,y_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_SVM = SVC(kernel=\"rbf\",C=50,gamma='scale',max_iter=2000, random_state=0)\n",
    "clf_SVM.fit(X_scale_rbs_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_scale_rbs_train,y_train, X_scale_rbs_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVM = SVC(kernel=\"rbf\",C=29,gamma='scale',max_iter=10000, random_state=0)\n",
    "clf_SVM.fit(X_scale_rbs_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_scale_rbs_train,y_train, X_scale_rbs_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con kernel RBF\n",
    "grid_SVM = {'C': list(range(1,51))}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_SVM_gridsearch = SVC(random_state=0, kernel=\"rbf\", gamma='scale', max_iter=10000)\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_SVM_gridsearch_f1= GridSearchCV(estimator = clf_SVM_gridsearch, param_grid = grid_SVM, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_SVM_gridsearch_f1.fit(X_scale_rbs_train,y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_SVM_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_SVM_gs_f1 = clf_SVM_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_SVM,X_scale_rbs_train,y_train, X_scale_rbs_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con kernel RBF\n",
    "grid_SVM = {'C': [6,7,8,9],'max_iter': [100,200,300,500, 600, 700]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_SVM_gridsearch = SVC(random_state=0, kernel=\"rbf\", gamma='scale')\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_SVM_gridsearch_f1= GridSearchCV(estimator = clf_SVM_gridsearch, param_grid = grid_SVM, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_SVM_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_SVM_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_SVM_gs_f1 = clf_SVM_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_SVM_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = clf_SVM\n",
    "selector = RFE(estimator, 1, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "selector.support_ \n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector2 = RFE(estimator, 3, step=1)\n",
    "selector2 = selector2.fit(X_train, y_train)\n",
    "selector2.support_ \n",
    "selector2.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[selector2.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Modelo que en Train cuadra exactamente los datos, pero en test casi no genera positivos\n",
    "clf_SVM = SVC(kernel=\"rbf\",C=10,max_iter=10000, random_state=0)\n",
    "clf_SVM.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo que siempre dice que no. Tanto en Train como en Test\n",
    "clf_SVM = SVC(kernel=\"rbf\",C=0.1,max_iter=10000, random_state=0)\n",
    "clf_SVM.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_SVM,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance \n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3) \n",
    "# Fit the data \n",
    "clf_KNN.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_KNN,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(1, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con KNN\n",
    "grid_KNN = {'n_neighbors': list(range(1, 21))}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_KNN_gridsearch = KNeighborsClassifier()\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_KNN_gridsearch_f1= GridSearchCV(estimator = clf_KNN_gridsearch, param_grid = grid_KNN, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_KNN_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_KNN_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_KNN_gs_f1 = clf_KNN_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_KNN_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con KNN\n",
    "grid_KNN = {'n_neighbors': list(range(2, 21))}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_KNN_gridsearch = KNeighborsClassifier()\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_KNN_gridsearch_f1= GridSearchCV(estimator = clf_KNN_gridsearch, param_grid = grid_KNN, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_KNN_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_KNN_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_KNN_gs_f1 = clf_KNN_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_KNN_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con KNN\n",
    "grid_KNN = {'n_neighbors': list(range(2, 21))}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_KNN_gridsearch = KNeighborsClassifier()\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_KNN_gridsearch_f1= GridSearchCV(estimator = clf_KNN_gridsearch, param_grid = grid_KNN, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_KNN_gridsearch_f1.fit(X_log_train, y_log_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_KNN_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_KNN_gs_f1 = clf_KNN_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_KNN_gs_f1,X_log_train,y_log_train, X_log_test,y_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con KNN\n",
    "grid_KNN = {'n_neighbors': list(range(2, 21))}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_KNN_gridsearch = KNeighborsClassifier()\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_KNN_gridsearch_f1= GridSearchCV(estimator = clf_KNN_gridsearch, param_grid = grid_KNN, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_KNN_gridsearch_f1.fit(X_scale_rbs_train,y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_KNN_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_KNN_gs_f1 = clf_KNN_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_KNN_gs_f1,X_scale_rbs_train,y_train, X_scale_rbs_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda py-xgboost  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_XGB=XGBClassifier(max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    silent=True,\n",
    "    objective='binary:logistic',\n",
    "    booster='gbtree',\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,\n",
    "    missing=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns=['Date_Account', 'birth_owner', 'birth_disponent', 'owner_card_date',\n",
    "       'Ord_Insurance', 'Ord_Insurance_amount', 'Ord_Household_Payment',\n",
    "       'Ord_Household_Payment_amount', 'Ord_Leasing', 'Ord_Empty',\n",
    "       'Ord_Empty_amount', 'num_inhabitants', 'municip 499',\n",
    "       'municip 500-1999', 'municip 2000-9999', 'municip 10000',\n",
    "       'num_cities', 'avg_salary', 'Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances',\n",
    "       'Num_Op_Collection', 'Num_Op_CashCredit', 'Num_Op_WithdrawalCash',\n",
    "       'Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal',\n",
    "       'Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative', 'Ord_Leasing_amount', 'ratio_urban_inhabitants',\n",
    "       'unemployment_rate_95', 'unemployment_rate_96', 'crimes_95_ratio',\n",
    "       'crimes_96_ratio', 'entrepreneurs_ratio', 'account_disponent_bin_0',\n",
    "       'account_disponent_bin_1', 'frequency_After_trans', 'frequency_Monthly',\n",
    "       'frequency_Weekly', 'sex_owner_F', 'sex_owner_M', 'owner_card_type_0',\n",
    "       'owner_card_type_1', 'owner_card_type_2', 'owner_card_type_3',\n",
    "       'sex_disponent_F', 'sex_disponent_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns=['Date_Account', 'birth_owner', 'birth_disponent', 'owner_card_date',\n",
    "       'Ord_Insurance', 'Ord_Insurance_amount', 'Ord_Household_Payment',\n",
    "       'Ord_Household_Payment_amount', 'Ord_Leasing', 'Ord_Empty',\n",
    "       'Ord_Empty_amount', 'num_inhabitants', 'municip 499',\n",
    "       'municip 500-1999', 'municip 2000-9999', 'municip 10000',\n",
    "       'num_cities', 'avg_salary', 'Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances',\n",
    "       'Num_Op_Collection', 'Num_Op_CashCredit', 'Num_Op_WithdrawalCash',\n",
    "       'Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal',\n",
    "       'Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative', 'Ord_Leasing_amount', 'ratio_urban_inhabitants',\n",
    "       'unemployment_rate_95', 'unemployment_rate_96', 'crimes_95_ratio',\n",
    "       'crimes_96_ratio', 'entrepreneurs_ratio', 'account_disponent_bin_0',\n",
    "       'account_disponent_bin_1', 'frequency_After_trans', 'frequency_Monthly',\n",
    "       'frequency_Weekly', 'sex_owner_F', 'sex_owner_M', 'owner_card_type_0',\n",
    "       'owner_card_type_1', 'owner_card_type_2', 'owner_card_type_3',\n",
    "       'sex_disponent_F', 'sex_disponent_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_XGB=XGBClassifier(max_depth=2,\n",
    "    learning_rate=0.99,\n",
    "    n_estimators=1,\n",
    "    silent=True,\n",
    "    objective='binary:logistic',\n",
    "    booster='gbtree',\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=50,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=0,\n",
    "    missing=None\n",
    ")\n",
    "clf_XGB.fit(X_train, y_train)\n",
    "eval_modelo_2 (clf_XGB,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a hacer un GridSearch con XGB\n",
    "grid_XGB = {'max_depth': [1,2,3,5,10,50],'learning_rate':[0.1,0,2,0.3,0.5,0.9,0.99], 'n_estimators':[1,2,3,10,100]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_XGB_gridsearch =clf_XGB\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_XGB_gridsearch_f1= GridSearchCV(estimator = clf_XGB_gridsearch, param_grid = grid_XGB, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_XGB_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_XGB_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_XGB_gs_f1 = clf_XGB_gridsearch_f1.best_estimator_  \n",
    "\n",
    "eval_modelo_2 (clf_XGB_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(clf_XGB_gs_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree\n",
    "from graphviz import Digraph\n",
    "plot_tree(clf_XGB_gs_f1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algunas visualizaciones de los modelos obtenidos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ya hemos visto algunas visualizaciones del impacto de las variables en la contratación de un préstamo con SHAP values y Partial Dependence Plot. A continuación vamos a continuar explorando los modelos obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c districtdatalabs yellowbrick "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features.radviz import RadViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a ver una primera visualización de todas las variables utilizadas con un gráfico radial (RadViz). \n",
    "classes = [\"No Loan\", \"Loan\"]\n",
    "visualizer = RadViz(classes=classes)\n",
    "visualizer.fit(X, y)     \n",
    "visualizer.transform(X)   \n",
    "visualizer.poof()         "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El gráfico no permite discriminar las cuentas que han contratado préstamo de las que no lo han hecho. Las 2 clases están \"apelotonadas\" una encima de la otra. Este gráfico lo podríamos haber incluido también al inicio del Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['Ord_Leasing', 'Num_Type_VYBER']\n",
    "\n",
    "X_plot = X[features].as_matrix()\n",
    "y_plot = y.as_matrix()\n",
    "\n",
    "visualizer = RadViz(classes=classes, features=features)\n",
    "\n",
    "visualizer.fit(X_plot, y_plot)      \n",
    "visualizer.transform(X_plot)  \n",
    "visualizer.poof()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot( x=\"Num_Type_VYBER\", y=\"Ord_Leasing\", data=df_original, fit_reg=False, hue='account_loan_bin', legend=False)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot( x=\"Num_Type_VYBER\", y=\"Ord_Leasing_amount\", data=df_original, fit_reg=False, hue='account_loan_bin', legend=False)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ahora vemos que seleccionando las variables que los modelos nos informan como más relevantes podemos discriminar claramente las cuentas que han contratado préstamo y las que no lo han hecho. A pesar de eso, este gráfico no nos aporta la sutileza que proporcionan los SHAP values al detectar que el efecto de 'Num_Type_VYBER'y 'Num_Op_Remittances' se puede invertir para valores muy elevados o muy bajos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Ord_Leasing', 'Ord_Leasing_amount','Num_Type_VYBER']\n",
    "\n",
    "X_plot = X[features].as_matrix()\n",
    "y_plot = y.as_matrix()\n",
    "\n",
    "visualizer = RadViz(classes=classes, features=features)\n",
    "\n",
    "visualizer.fit(X_plot, y_plot)      \n",
    "visualizer.transform(X_plot)  \n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Aunque en algunasejecuciones del código 'Num_Sym_Null2','Ord_Household_Payment_amount' han aparecido como variables importantes, visualmente no aportan tanto como 'Ord_Leasing', 'Num_Type_VYBER'y 'Num_Op_Remittances'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A continuación vamos a profundizar en el conocimiento de los modelos obtenidos mediante distintas visualizaciones: \n",
    "\n",
    "- Vamos a analizar si con más datos los modelos aún podrían mejorar\n",
    "\n",
    "- Vamos a analizar la clasificación obtenida por los modelos y su threshold óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from yellowbrick.model_selection import LearningCurve"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parece que el modelo aún podría beneficiarse de un incremento en el número de datos tanto en train como a la hora de generalizar, pero sobretodo a la hora de generalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a visualizar la curva de aprendizaje del modelo obtenido con Decision Tree\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_tree_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a probar si un incremento de las particiones podría mejorar el modelo. Decision Tree con 12 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=12, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_tree_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Se obtienen las mismas conclusiones que en el caso anterior, pero quizás ahora más claras al utilizar mayor número de datos para hacer el entrenamiento y menor numero de datos para las validaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest con 5 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_RF_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest con 12 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=12, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_RF_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En el caso del Random Forest, las conclusiones son similares a las obtenidas por Decision Tree, pero con un peor resultado de las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier con 5 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_GBC_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBC con 12 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=12, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_GBC_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En el caso de GBC, podemos ver que con pocos datos el modelo aprende los datos de train hasta conseguir un F1 Score del 100%, pero a medida que incrementa el número de datos, el modelo reduce el overfitting (generaliza mejor). Y parece que con mayor número de datos aún podría seguir mejorando."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En consecuencia, de lo anterior podemos extraer que uno de los puntos en la continuación del proyecto es que los modelos podrían beneficiarse de un mayor número de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import DiscriminationThreshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A continuación vamos a ver si con una visualización de las métricas del modelo podemos conseguir una mejor intuición del funcionamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "visualizer = DiscriminationThreshold(clf_tree_gs_f1)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.poof()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "visualizer = DiscriminationThreshold(clf_tree_gs_f1)\n",
    "visualizer.fit(X_test, y_test)  \n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precision: Por muy elevado que sitúe el threshold, el modelo predice como cuentas que han contratado préstamos, cuentas que no lo han contratado. Además la subida tan pronunciada de la curva nos indica que para las cuentas que no han contratado préstamo el modelo tiende a asignar un valor bajo de probabilidad. A partir de ese punto el F1 Score se estabiliza.\n",
    "\n",
    "Recall: El modelo asigna probabilidad=1 a más del 60% de las cuentas que han contratado préstamos. La poca pendiente de la curva nos indica que las cuentas que han contratado préstamo tiende a conseguir probabilidades elevadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "visualizer = DiscriminationThreshold(clf_RF_gs_f1)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precision: A partir de un momento todos los valores se corresponden a cuentas que han contratado préstamos, ya que la precisión es del 100%. Esto es muy positivo porque se asignan valores altos de probabilidad a las observaciones que efectivamente han contratado préstamos.\n",
    "\n",
    "Recall: Parece una curva con pendiente -1 o equivalentemente que la distribución de las probabilidades de las cuentas que han contratado préstamos es casi una uniforme entre las probabilidades 0% y 100% (aunque no lo sea exactamente). Por lo tanto este modelo no consigue discriminar las cuentas que contratan préstamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "visualizer = DiscriminationThreshold(clf_GBC_gs_f1)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A diferencia de los modelos anteriores, el modelo obtenido con GBC tiene un threshold muy bajo. En este caso asigna probabilidades muy bajas a las cuentas que no han contratado préstamo y probabilidades a partir de 15% aprox para los casos que si han contratado préstamo.\n",
    "\n",
    "Precision: La curva tiene pendiente muy elevada indicando una notable discriminación de las cuentas que tienen préstamo, respecto de las que no lo tienen.\n",
    "\n",
    "Recall: La curva tiene una pendiente baja (excepto para valores muy cercanos al 100%) indicando que las cuentas que contratan préstamos tienden a tener probabilidades elevadas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Un punto interesante que muestran los gráficos anteriores y que no ha salido hasta el momento es que el modelo que más nos puede interesar no tiene porque obtenerse por la optimización de varias métricas y puede requerir más análisis, por ejemplo en los casos que acabamos de ver también podría ser interesante modificar el threshold por defecto para obtener modelos con un F1 Score similar al del threshold óptimo pero con un threshold más bajo que permita obtener una precision y un recall más similares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Aunque no se ha realizado en el TFM este mismo análisis podría realizarse, por ejemplo, para la contratación de tarjetas de crédito "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xremit=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xremit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xremit[\"Num_Remit_exLoans\"]=df_original[\"Num_Op_Remittances\"]-df_original[\"Num_Sym_LoanPayment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xremit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[df_original['Num_Type_VYBER']>0]['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[df_original['Num_Type_Withdrawal']>400]['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13/(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
