{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tenencia del producto préstamo en el DataSet de Banca Checo  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a intentar extraer del datset generado que variables son las más relevantes para que una cuenta (account) haya contratado un péstamo (loan) y ver si de esta forma podemos generar un customer journey para conseguir que un cliente contrate un préstamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.core.multiarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para garantizar la replicabilidad del análisis\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/osmaac/master-data-science/master/DFTenenciaProductos.csv\"\n",
    "df_original=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzamos a revisar que el DF se haya importado correctamente\n",
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a analizar si hay missings al cargar los datos a Python\n",
    "df_original.columns[df_original.isnull().sum()!=0]\n",
    "#Vemos que las variables con missings provienen de variables que ya tenían esos missings en el DataFrame generado con R,\n",
    "#ya que el disponent (autorizado), los préstamos y las tarjetas no son productos que tengan asociados \n",
    "#todas las cuentas (sólo las cuentas que los hayan contratado) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos como se han importado las variables del DataFrame de R al DataFrame que vamos a utilizar en Python \n",
    "print(df_original.iloc[:,0:32].dtypes)\n",
    "print(df_original.iloc[:,31:61].dtypes)\n",
    "print(df_original.iloc[:,60:70].dtypes)\n",
    "#Observamos que las variables de factor y de fecha han modificado su tipo de variable, \n",
    "#por lo que tendremos que trabajar con ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos a formato fecha las variables que originalmente eran fecha en R\n",
    "df_original[[\"Date_Account\",\"birth_owner\", \"birth_disponent\", \"Date_Loan\", \"owner_card_date\"]]=df_original[[\"Date_Account\",\"birth_owner\", \"birth_disponent\", \"Date_Loan\", \"owner_card_date\"]].apply(pd.to_datetime)\n",
    "from datetime import datetime\n",
    "df_original['Date_Account']=df_original['Date_Account'].apply(datetime.toordinal)\n",
    "df_original['birth_owner']=df_original['birth_owner'].apply(datetime.toordinal)\n",
    "df_original['birth_disponent']=df_original['birth_disponent'].apply(datetime.toordinal)\n",
    "df_original['Date_Loan']=df_original['Date_Loan'].apply(datetime.toordinal)\n",
    "df_original['owner_card_date']=df_original['owner_card_date'].apply(datetime.toordinal)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De todas las variables de las que disponemos, vamos a seleccionar las que vamos a utilizar en este ejercicio:\n",
    "\n",
    "La  variable que vamos a predecir va a ser \"account_loan_bin\" y por tanto la denominaremos \"y\"\n",
    "\n",
    "Para este ejercicio no consideramos las variables que hemos obtenido en el mismo fichero que la variable a predecir (loan.csv):\n",
    "loan_id, Date_Loan, Amount_Loan, Duration_Loan, Payments_Loan, status, Status_Loan.\n",
    "\n",
    "Otras variables que no consideramos: account_id, client_id_owner, client_id_disponent, district ID y unnamed:0 porque \n",
    "son ID's descriptivas sin información para utilizar\n",
    "\n",
    "La variable disponent_card_type no aporta información, ya que no hay autorizados que hayan contratado card (tarjeta)\n",
    "\n",
    "Otras variables que no consideramos:district_name, region (nombre). Utilizamos el resto de la información de variables \n",
    "del fichero district.csv, que fundamentalemente aportan datos socio-económicos\n",
    "\n",
    "Haciendo referencia a district.csv , la información de crimes_95, crimes_96 y entrepreneurs la vamos a utilizar como ratio,\n",
    "ya que como veremos a continuación, de esta forma el número de habitantes del distrito Praga no distorsiona los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Las variables crimes_95, crimes_96 y entrepreneurs vamos a utilizarlas en formato ratio, tal y como calculamos en R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_95'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_95_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_96'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['crimes_96_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['entrepreneurs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_original['entrepreneurs_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame con las variables que vamos a considerar numéricas\n",
    "df_num=df_original[['Date_Account','birth_owner', 'birth_disponent','owner_card_date','Ord_Insurance', 'Ord_Insurance_amount',\n",
    "                    'Ord_Household_Payment','Ord_Household_Payment_amount', 'Ord_Loan_Payment', 'Ord_Leasing',\n",
    "                    'Ord_Empty', 'Ord_Empty_amount', 'num_inhabitants', 'municip < 499', 'municip 500-1999',\n",
    "                    'municip 2000-9999', 'municip > 10000', 'num_cities', 'avg_salary',  \n",
    "                    'Num_Type_Credit', 'Num_Type_VYBER', 'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances',\n",
    "                    'Num_Op_Collection','Num_Op_CashCredit', 'Num_Op_WithdrawalCash','Num_Op_WithdrawalCreditCard',\n",
    "                    'Num_Sym_Null', 'Num_Sym_Null2','Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal',\n",
    "                    'Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep', 'Num_Sym_LoanPayment', \n",
    "                    'Balance_in_negative','Ord_Loan_Payment_amount', 'Ord_Leasing_amount','ratio_urban_inhabitants',\n",
    "                    'unemployment_rate_95','unemployment_rate_96', 'crimes_95_ratio', 'crimes_96_ratio', 'entrepreneurs_ratio' ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame con las variables que vamos a considerar categóricas\n",
    "df_cat=df_original[['account_disponent_bin','frequency', 'sex_owner', 'owner_card_type',\n",
    "       'sex_disponent']]\n",
    "#Vemos que tipos tienen las variables que queremos que sean categóricas\n",
    "df_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ponemos las variables \"owner_card_type\" y \"account_disponent_bin\" como string para poder obtener dummies\n",
    "df_cat[\"owner_card_type\"]=df_cat[\"owner_card_type\"].astype(str)\n",
    "df_cat[\"account_disponent_bin\"]=df_cat[\"account_disponent_bin\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dumm=pd.get_dummies(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dumm.dtypes\n",
    "#Al pasar a dummies las variables, hemos incrementado en 8 el número total de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_num, df_cat_dumm], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a generar un primer modelo benchmark y vamos a ver si podemos obtener una simplificación de los datos con PCA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Antes de probar con modelos vamos a ver si reduciendo dimensionalidad conseguimos una primera intuición.\n",
    "\n",
    "Cuando pasemos a generar modelos, estos han de predecir si una cuenta (account) contrata préstamo (loan=1) o no (loan=0). Es la variable \"account_loan_bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df_original[\"account_loan_bin\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit_transform(X)\n",
    "plt.figure(dpi=120)\n",
    "plt.scatter(pca[y.values==0,0], pca[y.values==0,1], alpha=0.5, label='NO', s=2, color='navy')\n",
    "plt.scatter(pca[y.values==1,0], pca[y.values==1,1], alpha=0.5, label='YES', s=2, color='darkorange')\n",
    "plt.legend()\n",
    "plt.title('Producto préstamo')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Del gráfico anterior no consigo sacar nada en claro\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X)\n",
    "print(pca2.components_)\n",
    "print(pca2.explained_variance_ratio_)\n",
    "#De los componentes de momento tampoco sacamos ninguna conclusión. Las variables están en escalas muy distintas y por eso \n",
    "#el PCA genera resultados tan \"positivos\" en cuanto a explicabilidad de las 2 primeras componentes principales (74%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empezamos con modelos sencillos. Estos modelos han de predecir si una cuenta (account) contrata préstamo (loan=1) o no (loan=0)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos conjuntos de train y de test. Para el test usamos el 20% de las observaciones\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos una Regresión logística\n",
    "clf_LR=LogisticRegression(random_state=0) #vamos a incluir Random State en todos los modelos para poder reproducirlos\n",
    "clf_LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una función para poder evaluar el modelo, ver si genera overfitting, underfitting y tener detallada la matriz de\n",
    "#confusión de los modelos que generemos\n",
    "def eval_modelo (clf,X_train,y_train, X_test,y_test):\n",
    "    print(\"Datos de train:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_train,clf.predict(X_train))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    tn, fp, fn, tp=confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "    print(\"tn:\",tn,\" fp:\",fp,\" fn:\",fn,\" tp:\",tp)\n",
    "    print(\"Datos de test:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_test,clf.predict(X_test))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    tn_t, fp_t, fn_t, tp_t=confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "    print(\"tn:\",tn_t,\" fp:\",fp_t,\" fn:\",fn_t,\" tp:\",tp_t)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelo(clf_LR,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Probamos con un árbol de decisión\n",
    "clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelo(clf_tree,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados de estos modelos tan sencillos están siendo extraordinarios. Vamos a investigar las razones.\n",
    "Además como las clases están desbalanceadas vamos a ir comparando el efecto de incluir oversampling o no. \n",
    "Vamos a profundizar con Decission Trees ya que tiene menores requerimientos teóricos para las features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las clases a predecir (si la cuenta tiene prestamo=1 ó no tiene =0) están desbalanceadas\n",
    "y2=pd.DataFrame(y)\n",
    "sns.countplot(x=\"account_loan_bin\",data=y2, palette='hls')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2['account_loan_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos el porcentaje que representa cada clase:\n",
    "print(\"Las cuentas CON préstamo son el\", \"%.2f\" % (y2['account_loan_bin'].value_counts()[0]/len(y2['account_loan_bin'])*100) ,\"%\")\n",
    "print(\"Las cuentas SIN préstamo son el\", \"%.2f\" % (y2['account_loan_bin'].value_counts()[1]/len(y2['account_loan_bin'])*100) ,\"%\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Al estar las clases desbalanceadas hay que ir con cuidado porque un modelo que prediga siempre NO tendría un accuracy\n",
    "de casi el 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a querer dibujar Decision Trees. Importamos los paquetes necesarios para dibujarlos\n",
    "from io import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para dibujar un árbol\n",
    "def dibu_arb(tree):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(tree, out_file=dot_data,filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    return(Image(graph.create_png()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[36]\n",
    "#Parece que la variable \"Num_Sym_LoanPayment\" contiene toda la información de \"account_loan_bin\", aunque se han extraido \n",
    "#de ficheros distintos. Pero por el nombre se puede intuir que es así. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree.feature_importances_>0.10] #Vamos a ver las variables más importantes para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link interesante para ver como se realiza el cálculo de \"feature_importances\"_\n",
    "#https://medium.com/@srnghn/the-mathematics-of-decision-trees-random-forest-and-feature-importance-in-scikit-learn-and-spark-f2861df67e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c glemaitre imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "#Hemos tomado SMOTENC y no SMOTE para poder aplicar el algoritmo a variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver las columnas que vamos a denominar como categóricas cuando apliquemos SMOTE\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smo=SMOTENC(categorical_features=range(46,59),random_state=0)#Las variables categóricas van a ser de la 46 a la 59\n",
    "os_X,os_y=smo.fit_sample(X_train, y_train)\n",
    "columns = X_train.columns\n",
    "os_X = pd.DataFrame(data=os_X,columns=columns)\n",
    "os_y= pd.DataFrame(data=os_y,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeamos que SMOTENC funciona como esperábamos\n",
    "\n",
    "print(\"length of oversampled data is \",len(os_X))\n",
    "print(\"Number of loans=0 in oversampled data\",len(os_y[os_y['account_loan_bin']==0]))\n",
    "print(\"Number of loans=1\",len(os_y[os_y['account_loan_bin']==1]))\n",
    "print(\"Proportion of loans=0 is \",len(os_y[os_y['account_loan_bin']==0])/len(os_X))\n",
    "print(\"Proportion of loans=1 is \",len(os_y[os_y['account_loan_bin']==1])/len(os_X))\n",
    "\n",
    "os_bin=os_X[['account_disponent_bin_0','account_disponent_bin_1',\n",
    "       'frequency_After_trans', 'frequency_Monthly', 'frequency_Weekly',\n",
    "       'sex_owner_F', 'sex_owner_M', 'owner_card_type_0', 'owner_card_type_1',\n",
    "       'owner_card_type_2', 'owner_card_type_3', 'sex_disponent_F',\n",
    "       'sex_disponent_M']]\n",
    "\n",
    "print(\"unique de variables categóricas\",unique(os_bin))\n",
    "print(\"unique de variable y\",unique(os_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_os=os_clf_tree.fit(os_X,os_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelo(clf_tree_os,os_X,os_y, X_test, y_test)\n",
    "#Obtenemos los mismos resultados con y sin SMOTE. Lógicamente porque estamos suponiendo que la variable \n",
    "#'Num_Sym_LoanPayment' contiene la información de si la cuenta tiene un préstamo o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vemos que tener un préstamo correlaciona de forma muy significativa con las variables:Ord_Loan_Payment,Num_Sym_LoanPayment y \n",
    "#Ord_Loan_Payment_amount\n",
    "df_original.corr()[\"account_loan_bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos las correlaciones de las variables anteriores\n",
    "print(np.corrcoef(df_original[\"account_loan_bin\"],df_original[\"Ord_Loan_Payment\"]))\n",
    "print(np.corrcoef(df_original[\"account_loan_bin\"],df_original[\"Ord_Loan_Payment_amount\"]))\n",
    "print(np.corrcoef(df_original[\"account_loan_bin\"],df_original[\"Num_Sym_LoanPayment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a ver qué resultados obtenemos con los modelos eliminando la variable 'Num_Sym_LoanPayment' (la que anteriormente había\n",
    "#salido como más relevante). Generamos un nuevo DataFrame\n",
    "X1=X.drop(['Num_Sym_LoanPayment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_treeX1=X1_clf_tree.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos oversampling\n",
    "smo=SMOTENC(categorical_features=range(45,58),random_state=0)# Modificamos rango porque hemos eliminado una variable\n",
    "os_X1,os_y1=smo.fit_sample(X1_train, y1_train)\n",
    "columns = X1_train.columns\n",
    "os_X1 = pd.DataFrame(data=os_X1,columns=columns)\n",
    "os_y1= pd.DataFrame(data=os_y1,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeamos que SMOTENC funciona como esperábamos\n",
    "\n",
    "print(\"length of oversampled data is \",len(os_X1))\n",
    "print(\"Number of loans=0 in oversampled data\",len(os_y1[os_y1['account_loan_bin']==0]))\n",
    "print(\"Number of loans=1\",len(os_y1[os_y1['account_loan_bin']==1]))\n",
    "print(\"Proportion of loans=0 is \",len(os_y1[os_y1['account_loan_bin']==0])/len(os_X1))\n",
    "print(\"Proportion of loans=1 is \",len(os_y1[os_y1['account_loan_bin']==1])/len(os_X1))\n",
    "\n",
    "os_bin=os_X1[['account_disponent_bin_0','account_disponent_bin_1',\n",
    "       'frequency_After_trans', 'frequency_Monthly', 'frequency_Weekly',\n",
    "       'sex_owner_F', 'sex_owner_M', 'owner_card_type_0', 'owner_card_type_1',\n",
    "       'owner_card_type_2', 'owner_card_type_3', 'sex_disponent_F',\n",
    "       'sex_disponent_M']]\n",
    "print(\"unique de variables categóricas\",unique(os_bin))\n",
    "print(\"unique de variable y\",unique(os_y1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que el oversampling funciona bien, no lo vamos a chequear las próximas ocasiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osX1_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_osX1=osX1_clf_tree.fit(os_X1,os_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los modelos\n",
    "print(\"Sin Oversampling\")\n",
    "eval_modelo(clf_treeX1,X1_train,y1_train, X1_test, y1_test)\n",
    "print(\"Con Oversampling\")\n",
    "eval_modelo(clf_tree_osX1,os_X1,os_y1, X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_treeX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_osX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.columns[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.columns[clf_tree_osX1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.columns[clf_treeX1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El modelo continua dando unos resultados espectaculares, vamos a ver que sucede si eliminamos la variable \n",
    "'Ord_Loan_Payment_amount'. Generamos un nuevo Data Frame X2, a partir de X1 (al que ya habíamos eliminado 1 variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X1.drop(['Ord_Loan_Payment_amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el modelo SIN oversampling\n",
    "X2_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_treeX2=X2_clf_tree.fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos oversampling\n",
    "smo=SMOTENC(categorical_features=range(44,57),random_state=0)# Modificamos rango porque hemos eliminado una nueva variable\n",
    "os_X2,os_y2=smo.fit_sample(X2_train, y2_train)\n",
    "columns = X2_train.columns\n",
    "os_X2 = pd.DataFrame(data=os_X2,columns=columns)\n",
    "os_y2= pd.DataFrame(data=os_y2,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el árbol con el DataFrame al hemos aplicado oversampling\n",
    "osX2_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_osX2=osX2_clf_tree.fit(os_X2,os_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los modelos\n",
    "print(\"Sin Oversampling\")\n",
    "eval_modelo(clf_treeX2,X2_train,y2_train, X2_test, y2_test)\n",
    "print(\"Con Oversampling\")\n",
    "eval_modelo(clf_tree_osX2,os_X2,os_y2, X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_treeX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_osX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train.columns[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.columns[clf_treeX2.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.columns[clf_tree_osX2.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El modelo continua dando resultados espectaculares, vamos a ver que sucede si eliminamos la variable Ord_Loan_Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el conjunto X3, a partir de X2, eliminando la variable 'Ord_Loan_Payment'\n",
    "X3=X2.drop(['Ord_Loan_Payment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el modelo SIN oversampling\n",
    "X3_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_treeX3=X3_clf_tree.fit(X3_train,y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos oversampling\n",
    "smo=SMOTENC(categorical_features=range(43,56),random_state=0)# Modificamos rango porque hemos eliminado una nueva variable\n",
    "os_X3,os_y3=smo.fit_sample(X3_train, y3_train)\n",
    "columns = X3_train.columns\n",
    "os_X3 = pd.DataFrame(data=os_X3,columns=columns)\n",
    "os_y3= pd.DataFrame(data=os_y3,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el modelo CON oversampling\n",
    "osX3_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_osX3=osX3_clf_tree.fit(os_X3,os_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los modelos\n",
    "print(\"Sin Oversampling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Oversampling\")\n",
    "eval_modelo(clf_tree_osX3,os_X3,os_y3, X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Con Oversampling estoy \"forzando\" al modelo a generar más positivos  (tp y fp), y en este caso se ve perfectamente como\n",
    "con oversampling mejoro el recall (porque tengo más positivos), pero empeoro la precision porque no los estoy prediciendo\n",
    "correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_treeX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_osX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X3_train.columns[19])#Número de un tipo especial de reintegros\n",
    "print(X3_train.columns[22])#Número de transferencias enviadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.columns[clf_treeX3.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.columns[clf_tree_osX3.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_treeX3.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(clf_treeX3.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_original.corr()[\"account_loan_bin\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Después de eliminar las variables que más suenan a \"préstamo\", vamos a ver que sucede si eliminamos la variable Num_Type_VYBER,\n",
    "que es la de mayor importancia.Esta variable se corresponde con un tipo especial de reintegros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4=X3.drop(['Num_Type_VYBER'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el modelo SIN oversampling\n",
    "X4_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_treeX4=X4_clf_tree.fit(X4_train,y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos oversampling\n",
    "smo=SMOTENC(categorical_features=range(42,55),random_state=0)# Modificamos rango porque hemos eliminado una variable\n",
    "os_X4,os_y4=smo.fit_sample(X4_train, y4_train)\n",
    "columns = X4_train.columns\n",
    "os_X4 = pd.DataFrame(data=os_X4,columns=columns)\n",
    "os_y4= pd.DataFrame(data=os_y4,columns=['account_loan_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el modelo CON oversampling\n",
    "osX4_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)\n",
    "clf_tree_osX4=clf_tree.fit(os_X4,os_y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos los modelos\n",
    "print(\"Sin Oversampling\")\n",
    "eval_modelo(clf_treeX4,X4_train,y4_train, X4_test, y4_test)\n",
    "print(\"Con Oversampling\")\n",
    "eval_modelo(clf_tree_osX4,os_X4,os_y4, X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Con los datos de X4 vemos que el oversampling genera el mismo efecto que en el caso de X3, mejora recall y empeora precision.\n",
    "Además, al eliminar la variable de 'Num_Type_VYBER' es destacable que el modelo que obtenemos tiende a generar un mayor número \n",
    "de positivos, pero estos positivos resultan ser falsos positivos en su mayoría "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considero que el oversampling no me está aportando nada y dejo de utilizarlo en el resto del Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_treeX4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_osX4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Me quedo con el DataSet X3 no elimino la variable Num_Type_VYBER, ya que los resultados, aunque son peores que inicialmente, son ahora más razonables (no parece que exista una variable que contenga toda la información de \"y\"=\"account_loan_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajamos a continuación sobre las variables con las que nos hemos quedado"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a seguir con árboles ya que es un modelo sencillo y que podría aportar explicabilidad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a hacer scaling, aplicado a árboles no debería tener un gran impacto, pero vamos a testearlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a probar Robust Scaling, partiendo del DataFrame X3 (después de eliminar las variables que parece que contenían \n",
    "#la información de si una cuenta ha contratado préstamo o no lo ha contratado)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rbs = RobustScaler()\n",
    "columns = X3.columns\n",
    "rbs_scale = rbs.fit_transform(X3)\n",
    "X=pd.DataFrame(rbs_scale,columns=columns)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling (el modelo con el conjunto X3 es el mismo que generamos en el análisis\n",
    "#anterior de variables)\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Scaling\")\n",
    "eval_modelo(X_clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados con Robust Scaling no mejoran, así que vamos a probar con Standard Scaling aunque en un modelo de\n",
    "Decision Tree este modificación acostumbrará a tener poco impacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "columns = X3.columns\n",
    "scl_scale = scl.fit_transform(X3)\n",
    "X=pd.DataFrame(scl_scale,columns=columns)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree_=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling (el modelo con el conjunto X3 es el mismo que generamos en el análisis\n",
    "#anterior de variables)\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Scaling\")\n",
    "eval_modelo(clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a probar si con el scaling, cuando hacemos PCA podemos obtener una representación simple de los datos. \n",
    "#Sé que va a ser difícil obtener una representación tan sencilla del Data Frame pero lo probamos.\n",
    "pca = PCA(n_components=2).fit_transform(X)\n",
    "plt.figure(dpi=120)\n",
    "plt.scatter(pca[y.values==0,0], pca[y.values==0,1], alpha=0.5, label='NO', s=2, color='navy')\n",
    "plt.scatter(pca[y.values==1,0], pca[y.values==1,1], alpha=0.5, label='YES', s=2, color='darkorange')\n",
    "plt.legend()\n",
    "plt.title('Producto préstamo')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Del gráfico anterior no consigo sacar nada en claro\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X)\n",
    "print(pca2.components_)\n",
    "print(pca2.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De las componentes principales de momento tampoco sacamos ninguna conclusión, pero al haber escalado los datos ahora obtenemos un dato más razonable de variabilidad explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling tampoco ha funcionado mejor que sin scaling. Aplicamos scaling sólo a las variables numéricas\n",
    "print(X3.columns)\n",
    "print(X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos las variables numéricas de las que consideramos categóricas\n",
    "X3_cat=X3[['account_disponent_bin_0','account_disponent_bin_1',\n",
    "       'frequency_After_trans', 'frequency_Monthly', 'frequency_Weekly',\n",
    "       'sex_owner_F', 'sex_owner_M', 'owner_card_type_0', 'owner_card_type_1',\n",
    "       'owner_card_type_2', 'owner_card_type_3', 'sex_disponent_F',\n",
    "       'sex_disponent_M']]\n",
    "X3_num=X3[['Date_Account', 'birth_owner', 'birth_disponent', 'owner_card_date',\n",
    "       'Ord_Insurance', 'Ord_Insurance_amount', 'Ord_Household_Payment',\n",
    "       'Ord_Household_Payment_amount', 'Ord_Leasing', 'Ord_Empty',\n",
    "       'Ord_Empty_amount', 'num_inhabitants', 'municip < 499',\n",
    "       'municip 500-1999', 'municip 2000-9999', 'municip > 10000',\n",
    "       'num_cities', 'avg_salary', 'Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances',\n",
    "       'Num_Op_Collection', 'Num_Op_CashCredit', 'Num_Op_WithdrawalCash',\n",
    "       'Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal',\n",
    "       'Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative', 'Ord_Leasing_amount', 'ratio_urban_inhabitants',\n",
    "       'unemployment_rate_95', 'unemployment_rate_96', 'crimes_95_ratio',\n",
    "       'crimes_96_ratio', 'entrepreneurs_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos con el Robust Scaling\n",
    "columns = X3_num.columns\n",
    "X3_scale = rbs.fit_transform(X3_num)\n",
    "X3_scale=pd.DataFrame(X3_scale,columns=columns)\n",
    "X = pd.concat([X3_scale,X3_cat], axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree_=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Robust Scaling sólo en variables numéricas\")\n",
    "eval_modelo(clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En este caso, el robust scaling tampoco mejora los resultados que teníamos originalmente. Probamos otra alternativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos con min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X3_num.columns\n",
    "X3_scale = minmax.fit_transform(X3_num)\n",
    "X3_scale=pd.DataFrame(X3_scale,columns=columns)\n",
    "X = pd.concat([X3_scale,X3_cat], axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=5,random_state=0)#Con scaling\n",
    "clf_tree_=X_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comparamos los modelos con y sin scaling\n",
    "print(\"Sin Scaling\")\n",
    "eval_modelo(clf_treeX3,X3_train,y3_train, X3_test, y3_test)\n",
    "print(\"Con Scaling\")\n",
    "eval_modelo(clf_tree,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Con scaling MinMax el modelo casi no genera predicciones positivas y el accuracy se obtiene por un modelo que básicamente\n",
    "predice en test y train que la cuenta no contrata préstamo y al estar las clases desbalanceadas obtenemos ese Acuraccy (85% aprox), pero muy mal Recall y Precision"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hasta el momento hemos visto que en el dataset que habíamos generado habían 3 variables que \"contenían\" la información de la variable que queríamos predecir y también hemos visto que, en el caso de Decision Trees, las técnicas de Oversampling y de Scaling tal y como las hemos aplicado no mejoran los modelos iniciales."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a trabajar a continuación sobre las features numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X3_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir del DataFrame X3 creamos un DataFrame que contenga el log natural de las variables numéricas\n",
    "cols = X3_num.columns\n",
    "X3_log=pd.DataFrame(X3_num,columns=columns)#También podríamos hacer un copy del DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el logaritmo de las variables que consideramos numéricas\n",
    "cols=X3_num.columns\n",
    "for col in cols:\n",
    "    X3_log[col]=X3_log[col]+1.1 #Para evitar negativos al aplicar el logaritmo añadimos 1.1 (las variables son >=0)\n",
    "    X3_log[col]=np.log(X3_log[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hemos diminuido la variabilidad de las features\n",
    "X3_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame a partir del DataFrame X3 (una vez eliminadas las 3 variables que contenían la información de la variable\n",
    "#a predecir), aplicando logaritmo a las variables que consideramos numéricas y dejando las categóricas igual.\n",
    "X_log= pd.concat([X3_log,X3_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Adicionalmente al DataFrame anterior, vamos a crear un nuevo DataFrame binarizando las variables que tienen el número de operaciones (pasan de tener el número de operaciones a decir si la cuenta ha realizado ese tipo de operativa o no) y eliminando las columnas que contienen el sufijo \"_amount\" (sólo queremos reflejar si se ha realizado un tipo de operativa o no se ha realizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_bin=['Ord_Insurance', 'Ord_Household_Payment','Ord_Leasing', 'Ord_Empty','Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances','Num_Op_Collection', 'Num_Op_CashCredit', \n",
    "       'Num_Op_WithdrawalCash','Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal','Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative']\n",
    "\n",
    "col_out=['Ord_Insurance_amount','Ord_Household_Payment_amount','Ord_Empty_amount', 'Ord_Leasing_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X3.columns\n",
    "X3_bin=pd.DataFrame(X3,columns=cols)\n",
    "X3_bin=X3_bin.drop(col_out, axis=1)#Eliminamos las columnas de amount\n",
    "X3_bin=X3_bin.drop(col_to_bin, axis=1)#Eliminamos las columnas a binarizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el dataset que queremos binarizar\n",
    "X3_to_bin=X3[['Ord_Insurance', 'Ord_Household_Payment','Ord_Leasing', 'Ord_Empty','Num_Type_Credit', 'Num_Type_VYBER',\n",
    "       'Num_Type_Withdrawal', 'Num_Op_Null', 'Num_Op_Remittances','Num_Op_Collection', 'Num_Op_CashCredit', \n",
    "       'Num_Op_WithdrawalCash','Num_Op_WithdrawalCreditCard', 'Num_Sym_Null', 'Num_Sym_Null2',\n",
    "       'Num_Sym_Pension', 'Num_Sym_Insurance', 'Num_Sym_NegBal','Num_Sym_Household', 'Num_Sym_Statement', 'Num_Sym_IntDep',\n",
    "       'Balance_in_negative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que para cada observación de cada variable asigna 1 si el valor>0 y 0 en otro caso (no tenemos valores negativos)\n",
    "def binario(x):\n",
    "    if x>0:\n",
    "        x=1\n",
    "    else:\n",
    "        x=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos la función anterior a las variables que deseamos binarizar \n",
    "for col in col_to_bin:\n",
    "    X3_to_bin[col]=X3_to_bin[col].apply(binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X3_to_bin=X3_to_bin.astype(str)\n",
    "X3_to_bin=pd.get_dummies(X3_to_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame a partir del DataFrame X3 (una vez eliminadas las 3 variables que contenían la información de la variable\n",
    "#dependiente), binarizando las variables que contaban el número de operaciones.\n",
    "X_bin= pd.concat([X3_bin,X3_to_bin], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con los nuevos DataFrames de features vamos a intentar encontrar el mejor Decision Tree y ver cuales son las variables más significativas para dicho modelo, que podrían servir par establecer un custome journey del cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los DataFrames con los que vamos a trabajar son:\n",
    "#X_orig: El Dataframe con el que habíamos trabajado antes eliminando 3 variables, también lo llamábamos X3.\n",
    "X=X3\n",
    "#X_log: Es el Dataframe X_orig pero haciendo el logaritmo natural a las variables numéricas\n",
    "#X_bin: Es el Dataframe X_orig pero binarizando las variables que contaban cuantas operaciones de cada tipo se habían realizado\n",
    "#en cada cuenta, ahora decimos si la cuenta tiene ese tipo de operativa o no, y eliminando las variables que cuantificaban los\n",
    "#importes de dicha operativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Inicialmente pensaba considerar como única métrica la precisión (quería que el modelo minimizase los falsos positivos,\n",
    "pero en vista de los resultados de los modelos anteriores, en los que el recall (el % de positivos que acierto) \n",
    "puede ser muy bajo voy a comenzar a monitorizar también el F1 Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incluimos la métrica del F1 Score en la evaluación de los modelos. Modificamos la función anterior de evaluación\n",
    "def eval_modelo_2 (clf,X_train,y_train, X_test,y_test):\n",
    "    print(\"Datos de train:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_train,clf.predict(X_train))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_train,clf.predict(X_train))*100, \"%\")\n",
    "    print(\"El F1 Score es\",f1_score(y_train,clf.predict(X_train))*100,\"%\")\n",
    "    tn, fp, fn, tp=confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "    print(\"tn:\",tn,\" fp:\",fp,\" fn:\",fn,\" tp:\",tp)\n",
    "    print(\"Datos de test:\")\n",
    "    print(\"El accuracy es\",accuracy_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    print(\"La precision es\",precision_score(y_test,clf.predict(X_test))*100, \"%\")\n",
    "    print(\"El recall es\",recall_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    print(\"El F1 Score es\",f1_score(y_test,clf.predict(X_test))*100,\"%\")\n",
    "    tn_t, fp_t, fn_t, tp_t=confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "    print(\"tn:\",tn_t,\" fp:\",fp_t,\" fn:\",fn_t,\" tp:\",tp_t)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a definir la parrilla para realizar Randomized Grid Search\n",
    "\n",
    "# Máximo número de niveles en el árbol. Damos una distribución con mayor probabilidad en valores pequeños\n",
    "max_depth1 = [int(x) for x in np.linspace(2, 20, num = 10)]#\"Sobreponderamos\" árboles con poca profundidad\n",
    "max_depth2 =[int(x) for x in np.linspace(30, 100, num = 4)]\n",
    "max_depth=max_depth1 + max_depth2\n",
    "\n",
    "# Mínimo número de observaciones en cada hoja. Damos una distribución con mayor probabilidad en los valores más elevados\n",
    "min_samples_leaf_1 = [int(x) for x in np.linspace(5, 50, num = 4)]\n",
    "min_samples_leaf_2 = [int(x) for x in np.linspace(60, 100, num = 10)]\n",
    "min_samples_leaf=min_samples_leaf_1+min_samples_leaf_2\n",
    "\n",
    "# Hemos asignado mayor número de casos a los parámetros que podrían facilitar la explicabilidad del Decision Tree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la grid aleatoria\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(random_state=0)\n",
    "#Creamos una versión para optimizar la precision\n",
    "clf_tree_random_p= RandomizedSearchCV(random_state=0,estimator = clf_tree, param_distributions = random_grid, n_iter = 100, cv = 5,scoring=\"precision\")\n",
    "#Creamos una versión para optimizar el F1 Score\n",
    "clf_tree_random_f1= RandomizedSearchCV(random_state=0,estimator = clf_tree, param_distributions = random_grid, n_iter = 100, cv = 5,scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzamos por el DataFrame X (el X3 anterior)\n",
    "#Generamos conjuntos de train y el de test. Para el test usamos el 20% de las observaciones\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_tree_random_p.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_p.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trabajamos ahora con el mejor modelo encontrado en el Randomized Search, optimizando la precision. Entrenamos ahora el modelo\n",
    "#con todos los datos de train y luego lo evaluaremos con un conjunto de test no utilizado en la estimación\n",
    "clf_tree_p = clf_tree_random_p.best_estimator_\n",
    "clf_tree_p.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelo_2 (clf_tree_p,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parece que el modelo anterior produce overfitting, sobretodo en la métrica del Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_p.feature_importances_>0.10]\n",
    "#Las variables que obtenemos de este árbol que parece que produce overfitting son las que habíamos visto anteriormente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score\n",
    "\n",
    "clf_tree_random_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_f1.best_params_)\n",
    "\n",
    "clf_tree_f1 = clf_tree_random_f1.best_estimator_  \n",
    "clf_tree_f1.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_tree_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atención: obtengo mejor precision en el modelo que optimiza F1 Score que en el que optimiza Precision. Dado que el coste  \n",
    "computacional es bajo, creo que va a ser mejor aplicar GridSearch CV en lugar de RandomizedGridSearchCV, para no obtener \n",
    "resultados incoherentes por estar utilizando Randomized GridSearch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comparando el modelo que optimizamos el F1 Score, respecto al que optimizamos la precision, creo que es mejor el que optimiza\n",
    "el F1 Score porque aunque la precision puede bajar un poco, el recall aumenta de forma más significativa. Esto lo consigue \n",
    "generando un mayor número de positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos el árbol anterior como árbol de referencia ya que ofrece el mejor balance de Precision-Recall\n",
    "clf_tree_best=clf_tree_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parece que los modelos anteriores overfittean. Vamos a probar un modelo más sencillo\n",
    "clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=3,random_state=0)\n",
    "clf_tree.fit(X_train,y_train)\n",
    "eval_modelo_2(clf_tree,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_benchmark=clf_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.columns[19])\n",
    "print(X_train.columns[25])\n",
    "print(X_train.columns[22])\n",
    "print(X_train.columns[24])\n",
    "print(X_train.columns[36])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Interpretando el árbol anterior, lo que obtenemos es que, mayoritariamente, las cuentas que contratan préstamos son las que:\n",
    "--Num_Type_Viber > 0.5 (reintegros del tipo especial Vyber)\n",
    "--Num_Op_Remittances > 0.5 (envios/transferencias a otros bancos). Este podría ser un indicador de la solvencia y por tanto\n",
    "le encuentro sentido a su aparición\n",
    "--Ord_Leasing Amount<=501,5 (cargos automáticos por Leasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_best)\n",
    "# El árbol que hemos obtenido a partir del Randomized Grid Search es mucho más complejo, y por tanto, difícil de interpretar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_f1.feature_importances_>0.10]\n",
    "#A pesar de la mayor complejidad de este modelo, las variables que muestra como más importantes son las mismas que en el de\n",
    "#max_depth=3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De momento parece que la información aportada por los modelos obtenidos con randomized search y un modelo sencillo con\n",
    "criterio experto aportan resultados bastante similares en cuanto a las features relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a ver si la manipulación de variables que habíamos realizado anteriormente puede mejorar el modelo\n",
    "#Comenzamos por el DataFrame X_log\n",
    "#Generamos conjuntos de train y de test. Para el test usamos el 20% de las observaciones\n",
    "X_log_train, X_log_test, y_log_train, y_log_test = train_test_split(X_log, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_random_p.fit(X_log_train, y_log_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_p.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_p = clf_tree_random_p.best_estimator_  \n",
    "clf_tree_p.fit(X_log_train,y_log_train)\n",
    "eval_modelo_2(clf_tree_p,X_log_train, y_log_train,X_log_test, y_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_tree_p.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizamos ahora el F1 Score\n",
    "clf_tree_random_f1.fit(X_log_train, y_log_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_f1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_f1 = clf_tree_random_f1.best_estimator_  \n",
    "clf_tree_f1.fit(X_log_train, y_log_train)\n",
    "eval_modelo_2 (clf_tree_f1,X_log_train, y_log_train,X_log_test, y_log_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atención: obtengo mejor Precision en el modelo que optimiza F1 Score que en el que optimiza Precision. Dado que el coste  \n",
    "computacional es bajo, creo que va a ser mejor aplicar GridSearch CV en lugar de RandomizedGridSearchCV, para no obtener \n",
    "resultados incoherentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log.columns[clf_tree_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parece que los modelos anteriores overfittean. Vamos a probar un modelo más sencillo\n",
    "clf_tree = DecisionTreeClassifier(min_samples_leaf=20,max_depth=3,random_state=0)\n",
    "clf_tree.fit(X_log_train, y_log_train)\n",
    "eval_modelo_2(clf_tree,X_log_train, y_log_train,X_log_test, y_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log.columns[clf_tree_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que hemos obtenido features muy similares probando con técnicas más complejas como Randomized Search y con \n",
    "criterio experto o lo que podríamos haber obtenido a partir de un modelo benchmark inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A continuación seguimos con el DataFrame X_bin, en el que hemos binarizado las variables que contaban el número de veces que\n",
    "#produce una operativa\n",
    "#Generamos conjuntos de train y de test. Para el test usamos el 20% de las observaciones\n",
    "X_bin_train, X_bin_test, y_bin_train, y_bin_test = train_test_split(X_bin, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_random_p.fit(X_bin_train, y_bin_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_p.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_p = clf_tree_random_p.best_estimator_  \n",
    "clf_tree_p.fit(X_bin_train,y_bin_train)\n",
    "eval_modelo_2(clf_tree_p,X_bin_train, y_bin_train,X_bin_test, y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin.columns[clf_tree_p.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizamos ahora el F1 Score\n",
    "clf_tree_random_f1.fit(X_bin_train, y_bin_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_random_f1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_f1 = clf_tree_random_f1.best_estimator_  \n",
    "clf_tree_f1.fit(X_bin_train, y_bin_train)\n",
    "eval_modelo_2 (clf_tree_f1,X_bin_train, y_bin_train,X_bin_test, y_bin_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Con el DataFrame en el que binarizamos las variables, los resultados son claramente los peores obtenidos hasta el momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin.columns[clf_tree_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los DataFrames aplicando logaritmo y binarizando no mejoran el resultado del DataFrame original, se puede entender porque el\n",
    "modelo que estamos aplicando es un árbol.\n",
    "\n",
    "También estamos viendo que consistentemente las variables que son más relevantes son:\n",
    "--Num_Type_VYBER\n",
    "--Num_Op_Remittances\n",
    "--Ord_Household_Payment_amount\n",
    "--Ord_Leasing\n",
    "\n",
    "A continuación vamos a aplicar GridSearch con el conjunto de datos procedente de X3 (datos originales menos 3 variables)\n",
    "y vamos a ver que variables nos salen como más relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos la misma matriz de hiperparámetros\n",
    "grid=random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=StratifiedKFold(n_splits=5, random_state=0,shuffle=False)\n",
    "#Probamos con esta técnica por si el hecho que la Precision salga mejor optimizando F1 Score que optimizando Precision es por\n",
    "#algún factor aleatorio al aplicar Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los modelos para hacer la búsqueda de hiperparámetros \n",
    "clf_tree = DecisionTreeClassifier(random_state=0)\n",
    "#Creamos una versión para optimizar la precision\n",
    "clf_tree_gridsearch_p= GridSearchCV(estimator = clf_tree, param_grid = grid, cv=k, scoring=\"precision\")\n",
    "#Creamos una versión para optimizar el F1 Score\n",
    "clf_tree_gridsearch_f1= GridSearchCV(estimator = clf_tree, param_grid = grid, cv=k, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre Precision\n",
    "\n",
    "clf_tree_gridsearch_p.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_gridsearch_p.best_params_)\n",
    "\n",
    "clf_tree_gs_p = clf_tree_gridsearch_p.best_estimator_  \n",
    "clf_tree_gs_p.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_tree_gs_p,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos las features de mayor relevancia en el modelo\n",
    "X.columns[clf_tree_gs_p.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score\n",
    "\n",
    "clf_tree_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_tree_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_tree_gs_f1 = clf_tree_gridsearch_f1.best_estimator_\n",
    "clf_tree_gs_f1.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_tree_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "¿Cómo puede ser que obtenga un mejor resultado en Precision cuando optimizo F1 que cuando optimizo precision?. Creo que tengo \n",
    "todos los Random State controlados. Entonces puede ser que al volver  entrenar el modelo con el conjunto completo de los datos\n",
    "de train, cambie el modelo y su evaluación.\n",
    "Aunque parece que el modelo produce overfitting, de momento vamos a considerar este modelo para realizar las interpretaciones, ya que en datos de test es el que mejor resultados muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la relevancia de las features en el modelo\n",
    "clf_tree_gs_f1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos que muchas features tienen relevancia cero  o prácticamente nula \n",
    "#Veamos las features de mayor relevancia en el modelo\n",
    "X.columns[clf_tree_gs_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibu_arb(clf_tree_gs_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizamos a continuación la interpretabilidad de los resultados obtenidos "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A pesar de de tener un árbol el modelo no es sencillo de interpretar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para ver el impacto de las variables en la probabilidad de que una cuenta tenga un préstamo vamos a aplicar Partial Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdpbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ruta interesante para entender el Partial Dependece Plot\n",
    "https://christophm.github.io/interpretable-ml-book/pdp.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "También vamos a utilizar Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge shap "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Páginas interesantes para interpretar Shap Values\n",
    "https://github.com/slundberg/shap\n",
    "http://www.f1-predictor.com/model-interpretability-with-shap/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzamos el análisis de los SHAP values\n",
    "explainer = shap.TreeExplainer(clf_tree_gs_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos los SHAP values para el train\n",
    "shap_values_train = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos tambien los SHAP values para el test\n",
    "shap_values_test = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de variable Num_Type_VYBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_train, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para el caso de Num_Type_VYBER, vemos que el tener este tipo de operativa incrementa la posibilidad de haber contratado\n",
    "un préstamo hasta en un 20% (aproximadamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la distribución de la variable y en cuantas observaciones tiene efecto esta feature\n",
    "plt.hist(X['Num_Type_VYBER'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En la distribución de la variable 'Num_Type_VYBER', vemos que la frecuencia disminuye a medida que se incrementa el número de 'Num_Type_VYBER', indicando que el Partial Dependence Plot puede ser menos relevante a medida que se incrementa 'Num_Type_VYBER' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Num_Type_VYBER']>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Para asegurar la consistencia del análisis de Partial Dependence vamos a analizar la correlación de esta variable con el resto\n",
    "#de variables\n",
    "X.corr()[\"Num_Type_VYBER\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que \"Num_Type_VYBER\" tiene correlación que podría ser elevada con \"Num_Sym_Null\" y \"Num_Op_WithdrawalCash\", entorno\n",
    "a un 0,50.\n",
    "\n",
    "Vamos a ver que conclusiones podemos obtener con SHAP Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de train. En los desplegables de X e Y hay que seleccionar la variable Num_Type_VYBER (X) y\n",
    "# Num_Type_VYBER effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_train[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de test. En los desplegables de X e Y hay que seleccionar la variable Num_Type_VYBER (X) y\n",
    "# Num_Type_VYBER effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_test[1], X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que en el caso de SHAP values, la relación entre el número de operaciones de tipo Vyber y su contribución a la probabilidad de contratar un préstamo no es monotónica, ni constante. En general, para valores bajos de Num_Type_VYBER (pero superiores a 0), esta característica incrementa la posibilidad de haber contratado préstamo, pero para valores elevados de esta variable hay parece contribuir negativamente. \n",
    "\n",
    "El efecto anterior puede explicar porque al binarizar las variables que contaban la frecuencia de ocurrencia de las distintas operativas (DataFrame \"X_bin\"), los resultados que obtenemos con los modelos son los peores."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El scatter plot que se muestra a continuación también muestra que las cuentas con mayor operativa de tipo Vyber, tienden a no haber contratado préstamos. Esta casuísitica debería analizarse en mayor profundidad, revisando dichas cuentas y viendo por ejemplo si contratan otro tipo de productos de crédito que no estén entrando en el fichero de loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X.Num_Type_VYBER, y)\n",
    "plt.xlabel(\"Num_Type_VYBER\")\n",
    "plt.ylabel(\"account_loan_bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos si podrían ser los leasings, pero parece que las cuentas con mayor operativa de tipo Vyber, tienden a no tener domiciliaciones por leasings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Num_Type_VYBER, X.Ord_Leasing)\n",
    "plt.xlabel(\"Num_Type_VYBER\")\n",
    "plt.ylabel(\"Ord_Leasing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de variable Num_Op_Remittances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Op_Remittances' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_train, model_features=X.columns, feature='Num_Op_Remittances')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Op_Remittances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Op_Remittances' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Op_Remittances')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Op_Remittances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para el caso de Num_Op_Remittances, vemos que el tener este tipo de operativa puede incrementar la posibilidad \n",
    "de haber contratado un préstamo hasta en más del 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Veamos la distribución de la variable y en cuantas observaciones tiene efecto esta feature\n",
    "plt.hist(X['Num_Op_Remittances'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Como en el caso anterior vemos que la frecuencia disminuye a medida que se incrementa 'Num_Op_Remittances', indicando que el Partial Dependence Plot puede ser menos relevante a medida que se incrementan los valores observados de esta variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Num_Op_Remittances']>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Para evaluar la consistencia del análisis de Partial Dependence vamos a analizar la correlación de esta variable con el resto\n",
    "#de variables\n",
    "X.corr()[\"Num_Op_Remittances\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que \"Num_Op_Remittances\" tiene correlación que podría ser elevada con \"Num_Sym_Null2\" (0,85), y \"Num_Type_Withdrawal\" (0,83) y algo menor con otras como \"Num_Sym_Household\" y \"Ord_Insurance\". Estas elevadas correlaciones pueden invalidar los resultados del análisis de Partial Dependence.\n",
    "\n",
    "Vamos a ver que conclusiones podemos obtener con SHAP Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values para conjunto de train. En los desplegables de X e Y hay que seleccionar la variable Num_Op_Remittances (X) y \n",
    "# Num_Op_Remittances effects (Y)\n",
    "\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_train[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de test. En los desplegables de X e Y hay que seleccionar la variable Num_Op_Remittances (X) y\n",
    "# Num_Op_Remittances effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_test[1], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Num_Op_Remittances, y)\n",
    "plt.xlabel(\"Num_Op_Remittances\")\n",
    "plt.ylabel(\"account_loan_bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Un número bajo de operaciones de Remittances/Envíos de dinero no parece implicar mayor probabilidad de contratar un préstamo (es normal ya que la mayoría de cuentas tienen un número bajo de Remittances y no han contratado préstamo). En cambio un número elevado de Remittances sí que implica una mayor probabilidad de haber contratado un préstamo.\n",
    "\n",
    "En mi opinión lo anterior tiene 2 lecturas, realizar un gran número de envíos, puede ser una muestra de calidad crediticia y por tanto de ser elegible para obtener un crédito. Pero también podría guardar relación con que la cuenta haya contratado un préstamo y sea la forma de pago (a pesar de haber eliminado inicialmente las variables: Ord_Loan_Payment,Num_Sym_LoanPayment y \n",
    "Ord_Loan_Payment_amount). En consecuencia se debería profundizar en la finalidad de las operaciones de Remittance.\n",
    "\n",
    "Como en el caso de Num_Type_VYBER, la forma de los SHAP values de Num_Op_Remittances nos muestra porqueal binaririzar las variables obtengo peores resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de variable Ord_Leasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Ord_Leasing' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_train, model_features=X.columns, feature='Ord_Leasing')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Leasing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdp_feature = pdp.pdp_isolate(model=clf_tree_gs_f1, dataset=X_test, model_features=X.columns, feature='Ord_Leasing')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Leasing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de Ord_Leasing, vemos que el tener este tipo de operativa disminuye la probabilidad de haber contratado un préstamo en un 10% aproximandamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la distribución de la variable y en cuantas observaciones tiene efecto esta feature\n",
    "plt.hist(X['Ord_Leasing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Ord_Leasing']>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para evaluar la consistencia del análisis de Partial Dependence vamos a analizar la correlación de esta variable con el resto\n",
    "#de variables\n",
    "X.corr()[\"Ord_Leasing\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que \"Ord_Leasing\" tiene correlación elevada con \"Ord_Leasing_amount \" (0,88) ya ambas son distintas de cero en los mismos casos y a medida que una de ellas crece la otra también debe hacerlo. Y la siguiente mayor correlación es con \"Num_Type_VYBER\" de 0,24. Si vemos el scatter plot de \"Ord_Leasing\" y \"Num_Type_VYBER\", vemos que valores altos de \"Num_Type_VYBER\" que \"perjudican\" la probabilidad de haber contratado un préstamo acostumbran a tener \"Ord_Leasing\"=0, que es un valor que no \"perjudica\" la probabilidad de haber contratado un préstamo y por tanto no podemos asumir que ambas variables contengan la misma información\n",
    "\n",
    "A continuación, vamos a ver que conclusiones podemos obtener con SHAP Values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Num_Type_VYBER, X.Ord_Leasing)\n",
    "plt.xlabel(\"Num_Type_VYBER\")\n",
    "plt.ylabel(\"Ord_Leasing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de train. En los desplegables de X e Y hay que seleccionar la variable Ord_Leasing (X) y\n",
    "#Ord_Leasing effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_train[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values para  conjunto de test. En los desplegables de X e Y hay que seleccionar la variable Ord_Leasing (X) y\n",
    "#Ord_Leasing effects (Y)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_test[1], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Ord_Leasing, y)\n",
    "plt.xlabel(\"Ord_Leasing\")\n",
    "plt.ylabel(\"account_loan_bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que tener Ord_Leasing=0, incrementa ligeramente la probabilidad de haber contratado un préstamo, mientras que Ord_Leasing=1 disminuye dicha probabilidad.\n",
    "\n",
    "Es también llamativo que ninguna de las cuentas que ha contratado un préstamo ha tenido activo las órdenes/domiciliaciones de Leasing (scatter plot). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Calculadora\" de SHAP values para las observaciones de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para cada observación i podemos ver el impacto de las distintas features en su probabilidad de haber contratado un préstamo\n",
    "i=52\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_test[1][i,:], feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para cada observación i podemos ver el valor de las variables que hemos seleccionado (las más significativas del modelo)\n",
    "X_test.iloc[i][['Num_Type_VYBER','Num_Op_Remittances','Ord_Leasing']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Esta calculadora podría hacerse para los valores de test (o para cualquier otro conjunto), simplemente cambiando en las celdas anteriores test por el conjunto que queramos analizar y calculando los SHAP values para dicho conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A continuación  vamos a ver qué resultados obtendríamos con Random Forest (un modelo más potente también basado en árboles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzamos a probar con un Random Forest sencillo: \n",
    "clf_RF= RandomForestClassifier(max_depth=30,min_samples_leaf=5,random_state=0,n_estimators=50)\n",
    "clf_RF.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_RF,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En este caso hemos mejorado ligeramente la precision respecto al Decision Tree que habíamos obtenido optimizando F1 Score en el apartado anterior (de 85,12% a 86,81%), pero hemos empeorado significativamente el Recall (de 72,02% a 55,24%). De todas formas, este modelo continuan mostrando las mismas features como las más relevantes (no aporta ninguna nueva). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[clf_RF.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Como el tiempo de ejecución es elevado dejamos, esta parte del código y el resultado, como texto:\n",
    "\n",
    "Basándonos en los parámetros del modelo de Decision Tree (max_depth=14,min_samples_leaf=5), vamos a buscar el número óptimo de estimadores (árboles) del Random Forest.\n",
    "\n",
    "#Vamos a probar con los parámetros del Decision Tree que estábamos tomando como referencia y vamos a optimizar n_estimators:\n",
    "#'max_depth': 14 y 'min_samples_leaf': 5\n",
    "clf_RF= RandomForestClassifier(max_depth=14,min_samples_leaf=5,random_state=0)\n",
    "n_estimators = [int(x) for x in np.linspace(100, 2000, num = 20)]\n",
    "grid_estimators = {'n_estimators': n_estimators}\n",
    "clf_RF_gridsearch_f1= GridSearchCV(estimator = clf_RF, param_grid = grid_estimators, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos los resultados con la optimización realizada sobre F1 Score para intentar obtener Precision y Recall equilibrados:\n",
    "\n",
    "clf_RF_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_RF_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_RF_gs_f1 = clf_RF_gridsearch_f1.best_estimator_  \n",
    "clf_RF_gs_f1.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados son:\n",
    "\n",
    "tuned hyperparameters :(best parameters)  {'n_estimators': 200}\n",
    "Datos de train:\n",
    "El accuracy es 96.38888888888889 %\n",
    "La precision es 99.51573849878935 %\n",
    "El recall es 76.25231910946196 %\n",
    "El F1 Score es 86.34453781512606 %\n",
    "tn: 3059  fp: 2  fn: 128  tp: 411\n",
    "Datos de test:\n",
    "El accuracy es 91.11111111111111 %\n",
    "La precision es 84.61538461538461 %\n",
    "El recall es 53.84615384615385 %\n",
    "El F1 Score es 65.8119658119658 %\n",
    "tn: 743  fp: 14  fn: 66  tp: 77\n",
    "\n",
    "Siendo peores que en la optimización obtenida por el Decision Tree simple.\n",
    "\n",
    "El parámetro encontrado por la optimización es número de estimadores/árboles=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replicamos el Random Forest obtenido en la optimización anterior\n",
    "clf_RF_gs_f1= RandomForestClassifier(max_depth=14,min_samples_leaf=5,n_estimators=200,random_state=0)\n",
    "clf_RF_gs_f1.fit(X_train, y_train)\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos a continuación las variables más relevantes para el modelo:\n",
    "X.columns[clf_RF_gs_f1.feature_importances_>0.10]\n",
    "#Estas variables coinciden con las que habíamos analizado anteriormente"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Como en el caso anterior vamos a dejar el código en formato texto, por el tiempo de ejecución. Vamos a probar con 200 árboles/estimadores y vamos a optimizar los parámetros:'max_depth' y'min_samples_leaf'\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_RF= RandomForestClassifier(n_estimators=200,random_state=0)\n",
    "\n",
    "#Probamos directamente con la optimización de F1 Score\n",
    "clf_RF_gridsearch_f1= GridSearchCV(estimator = clf_RF, param_grid = grid, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_RF_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_RF_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_RF_gs_f1 = clf_RF_gridsearch_f1.best_estimator_  \n",
    "clf_RF_gs_f1.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados de la optimización con 200 estimadores:\n",
    "\n",
    "tuned hyperparameters :(best parameters)  {'max_depth': 30, 'min_samples_leaf': 5}\n",
    "Datos de train:\n",
    "El accuracy es 96.66666666666667 %\n",
    "La precision es 99.52718676122932 %\n",
    "El recall es 78.10760667903524 %\n",
    "El F1 Score es 87.52598752598753 %\n",
    "tn: 3059  fp: 2  fn: 118  tp: 421\n",
    "Datos de test:\n",
    "El accuracy es 91.55555555555556 %\n",
    "La precision es 87.64044943820225 %\n",
    "El recall es 54.54545454545454 %\n",
    "El F1 Score es 67.24137931034483 %\n",
    "tn: 746  fp: 11  fn: 65  tp: 78\n",
    "\n",
    "En este caso hemos mejorado ligeramente la Precision respecto al Decision Tree (de 85,12% a 87,64%), pero hemos empeorado significativamente el Recall (de 72,02% a 54,54%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replicamos el Random Forest obtenido en la optimización anterior\n",
    "clf_RF_gs_f1= RandomForestClassifier(max_depth=30,min_samples_leaf=5,n_estimators=200,random_state=0)\n",
    "clf_RF_gs_f1.fit(X_train, y_train)\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En el caso de optimizar el F1 Scores con número de estimadores=200, las features más relevantes siguen siendo \n",
    "#las que habíamos visto anteriormente:\n",
    "X.columns[clf_RF_gs_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A continuación vamos a  realizar un GridSearch para Random Forest fijando el número de estimadores en 500 y con los mismos parámetros en Grid Search que con un sólo Decission Tree. Como la busqueda tarda bastante, dejo el código en formato Markdown y en la siguiente celda incluyo el resultado.\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_RF= RandomForestClassifier(n_estimators=500,random_state=0) # Empezamos fijando los estimadores en 500\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_RF_gridsearch_f1= GridSearchCV(estimator = clf_RF, param_grid = grid, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_RF_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_RF_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_RF_gs_f1 = clf_RF_gridsearch_f1.best_estimator_  \n",
    "clf_RF_gs_f1.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Resultado de la ejecución del código anterior (n_estimators=500):\n",
    "\n",
    "tuned hyperparameters :(best parameters)  {'max_depth': 30, 'min_samples_leaf': 5}\n",
    "Datos de train:\n",
    "El accuracy es 94.86111111111111 %\n",
    "La precision es 90.59633027522935 %\n",
    "El recall es 73.28385899814471 %\n",
    "El F1 Score es 81.02564102564102 %\n",
    "tn: 3020  fp: 41  fn: 144  tp: 395\n",
    "Datos de test:\n",
    "El accuracy es 92.11111111111111 %\n",
    "La precision es 81.57894736842105 %\n",
    "El recall es 65.03496503496503 %\n",
    "El F1 Score es 72.37354085603113 %\n",
    "tn: 736  fp: 21  fn: 50  tp: 93"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El resultado que hemos obtenido de la ejecución anterior es peor que el que hemos obtenido aplicando Decision Tree, aunque mejora los de n_estimators=200. Los resultados del modelo de Decision Tree eran:\n",
    "\n",
    "tuned hpyerparameters :(best parameters)  {'max_depth': 14, 'min_samples_leaf': 5}\n",
    "Datos de train:\n",
    "El accuracy es 97.91666666666666 %\n",
    "La precision es 94.78764478764478 %\n",
    "El recall es 91.09461966604823 %\n",
    "El F1 Score es 92.90444654683066 %\n",
    "tn: 3034  fp: 27  fn: 48  tp: 491\n",
    "Datos de test:\n",
    "El accuracy es 93.55555555555556 %\n",
    "La precision es 85.12396694214877 %\n",
    "El recall es 72.02797202797203 %\n",
    "El F1 Score es 78.03030303030305 %\n",
    "tn: 739  fp: 18  fn: 40  tp: 103\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Replicamos el Random Forest obtenido en la optimización anterior\n",
    "clf_RF_gs_f1= RandomForestClassifier(max_depth=30,min_samples_leaf=5,n_estimators=500,random_state=0)\n",
    "clf_RF_gs_f1.fit(X_train, y_train)\n",
    "eval_modelo_2 (clf_RF_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las features más relevantes siguen siendo las que habíamos visto anteriormente:\n",
    "X.columns[clf_RF_gs_f1.feature_importances_>0.10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A continuación  vamos a ver que resultados obtendríamos con un modelo más potente, tambien basado en árboles, como Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosideramos un primer modelo para probar\n",
    "clf_GBC = GradientBoostingClassifier(max_depth=4,random_state=0)\n",
    "clf_GBC.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_GBC,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados son espectaculares. Mejoran de forma muy sencilla y rápida los resultados anteriores. Aunque parece que continua habiendo Overfitting, sobretodo en la métrica de Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos cuales son las variables más significativas para este modelo \n",
    "X.columns[clf_GBC.feature_importances_>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muy fácilmente obtenemos modelos que aprenden el 100% de los datos de Train, aunque en este caso, claramente tiene overfitting\n",
    "clf_GBC = GradientBoostingClassifier(max_depth=10,random_state=0)\n",
    "clf_GBC.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_GBC,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muy fácilmente obtenemos modelos que aprenden el 100% de los datos de Train (sólo variando un parámetro)\n",
    "clf_GBC = GradientBoostingClassifier(n_estimators=1000,random_state=0)\n",
    "clf_GBC.fit(X_train,y_train)\n",
    "eval_modelo_2 (clf_GBC,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En comparación con el modelo anterior hemos conseguido ahora un modelo que genera más positivos y además los acierta, mejorando de esta forma el recall"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Como este código tarda bastante en ejecutarse lo ponemos como texto y utilizaremos sus resultados\n",
    "\n",
    "#Vamos a hacer un GridSearch para ver cuales son las variables más significativas de un modelo que a priori va a mejorar\n",
    "#bastante los modelos que hemos obtenido hasta ahora con Random Forest y Decision Trees:\n",
    "grid_GBC = {'max_depth': [3,4,5,7],'min_samples_leaf': [5,10,15,20], \n",
    "        'n_estimators':[100,500,1000,2000],'learning_rate': [0.05,0.1,0.2,0.5]}\n",
    "\n",
    "#Creamos el modelo para hacer la búsqueda de hiperparámetros\n",
    "clf_GBC_gridsearch = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "#Creamos una versión para optimizar el F1 Score (de los análisis anteriores hemos visto que da resultados más consistentes \n",
    "#la optimización de F1 Score que la de Precision (ofrece Recalls muy bajos)). Así que probamos directamente con F1 Score\n",
    "clf_GBC_gridsearch_f1= GridSearchCV(estimator = clf_GBC_gridsearch, param_grid = grid_GBC, cv=k, scoring=\"f1\")\n",
    "\n",
    "#Vemos ahora los resultados con la optimización realizada sobre F1 Score \n",
    "\n",
    "clf_GBC_gridsearch_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_GBC_gridsearch_f1.best_params_)\n",
    "\n",
    "clf_GBC_gs_f1 = clf_GBC_gridsearch_f1.best_estimator_  \n",
    "clf_GBC_gs_f1.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_GBC_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los resultados han sido:\n",
    "\n",
    "tuned hyperparameters :(best parameters)  {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_leaf': 15, 'n_estimators': 1000}\n",
    "Datos de train:\n",
    "El accuracy es 100.0 %\n",
    "La precision es 100.0 %\n",
    "El recall es 100.0 %\n",
    "El F1 Score es 100.0 %\n",
    "tn: 3061  fp: 0  fn: 0  tp: 539\n",
    "Datos de test:\n",
    "El accuracy es 97.66666666666667 %\n",
    "La precision es 95.52238805970148 %\n",
    "El recall es 89.5104895104895 %\n",
    "El F1 Score es 92.4187725631769 %\n",
    "tn: 751  fp: 6  fn: 15  tp: 128"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Este modelo supera al obtenido con Decision Trees.\n",
    "\n",
    "Matriz confusion Decision Trees= tn: 739  fp: 18  fn: 40  tp: 103\n",
    "\n",
    "Matriz confusion GBC=  tn: 751  fp: 6  fn: 15  tp: 128\n",
    "\n",
    "Vemos que hay una mejora relevante en todas las magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir de los datos obtenidos por la optimización reproducimos el modelo\n",
    "clf_GBC_gs_f1 = GradientBoostingClassifier(learning_rate= 0.2,max_depth=3,min_samples_leaf= 15,\n",
    "                                                       n_estimators= 1000,random_state=0)\n",
    "clf_GBC_gs_f1.fit(X_train,y_train)\n",
    "\n",
    "eval_modelo_2 (clf_GBC_gs_f1,X_train,y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos cuales son las variables más significativas para este modelo \n",
    "X.columns[clf_GBC_gs_f1.feature_importances_>0.09]\n",
    "#Bajamos un poco el umbral para ver si sale exactamente lo mismo que en el caso de Decision Tree y en este caso entraría\n",
    "#una nueva variable"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Las variables más significativas son similares a las de los modelos anteriores. Vamos a ver que explicabilidad podemos encontrar con SHAPE Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siguiendo las indicaciones de la página https://github.com/slundberg/shap, vemos que no hay una implementación rápida \n",
    "#para los modelos de Gradient Boosting Classifier y debemos utilizar la implementación genérica\n",
    "explainer = shap.KernelExplainer(clf_GBC_gs_f1.predict_proba,X_train, link=\"logit\")\n",
    "shap_values = explainer.shap_values(X_test,nsamples=2)\n",
    "#Incluimos un nsamples bajo para ver que el código se puede ejecutar pero no lo ejecutamos con nsamples alto porque tarda mucho\n",
    "#en ejecutarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con pocas samples, SHAPE values no funciona muy bien (no muestra valores), pero a continuación muestro una \"calculadora\" \n",
    "#para poder analizar el efecto de cada variable en una observación dada\n",
    "i=10\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][52,:], X_test.iloc[i,:])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vamos a analizar el efecto de las variables utilizando PDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Ord_Household_Payment_amount' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Ord_Household_Payment_amount')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Household_Payment_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Ord_Household_Payment_amount' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Ord_Household_Payment_amount')\n",
    "pdp.pdp_plot(pdp_feature, 'Ord_Household_Payment_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la distribución de la variable y en cuantas observaciones tiene efecto esta feature\n",
    "plt.hist(X['Ord_Household_Payment_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Ord_Household_Payment_amount']>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Para asegurar la consistencia del análisis de Partial Dependence vamos a analizar la correlación de esta variable con el resto\n",
    "#de variables\n",
    "X.corr()[\"Ord_Household_Payment_amount\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Las mayores corrleaciones en el caso de Ord_Household_Payment_amount se producen en los casos de:Ord_Household_Payment (0,52), Num_Sym_Household (0,38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.Ord_Household_Payment_amount, y)\n",
    "plt.xlabel(\"Ord_Household_Payment_amount\")\n",
    "plt.ylabel(\"account_loan_bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Type_VYBER' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Type_VYBER')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Type_VYBER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Op_Remittances' en X_train con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Op_Remittances')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Op_Remittances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el impacto de 'Num_Op_Remittances' en X_test con Partial Dependece Plot\n",
    "pdp_feature = pdp.pdp_isolate(model=clf_GBC_gs_f1, dataset=X_test, model_features=X.columns, feature='Num_Op_Remittances')\n",
    "pdp.pdp_plot(pdp_feature, 'Num_Op_Remittances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algunas visualizaciones de los modelos obtenidos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ya hemos visto algunas visualizaciones del impacto de las variables en la contratación de un préstamo con SHAP values y Partial Dependence Plot. A continuación vamos a continuar explorando los modelos obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c districtdatalabs yellowbrick "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features.radviz import RadViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a ver una primera visualización de todas las variables utilizadas con un gráfico radial (RadViz). \n",
    "classes = [\"No Loan\", \"Loan\"]\n",
    "visualizer = RadViz(classes=classes)\n",
    "visualizer.fit(X, y)     \n",
    "visualizer.transform(X)   \n",
    "visualizer.poof()         "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El gráfico no permite discriminar las cuentas que han contratado préstamo de las que no lo han hecho. Las 2 clases están \"apelotonadas\" una encima de la otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Ord_Leasing', 'Num_Type_VYBER', 'Num_Op_Remittances']\n",
    "\n",
    "X_plot = X[features].as_matrix()\n",
    "y_plot = y.as_matrix()\n",
    "\n",
    "visualizer = RadViz(classes=classes, features=features)\n",
    "\n",
    "visualizer.fit(X_plot, y_plot)      \n",
    "visualizer.transform(X_plot)   # Revisar con X y con X_plot\n",
    "visualizer.poof()         "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ahora vemos que seleccionando las variables que los modelo nos informan como más relevantes podemos discriminar claramente las cuentas que han contratado préstamo y las que no lo han hecho. A pesar de eso, este gráfico no nos aporta la sutileza que proporcionan los SHAP values al detectar que el efecto de 'Num_Type_VYBER'y 'Num_Op_Remittances' se puede invertir para valores muy elevados o muy bajos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A continuación vamos a profundizar en el conocimiento de los modelos obtenidos: \n",
    "\n",
    "- Vamos a analizar si con más datos los modelos aún podrían mejorar\n",
    "\n",
    "- Vamos a analizar la clasificación obtenida por los modelos y su threshold óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree con 5 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10) #Analisis con 10 tamaños distintos del DataSet entre 30% de los datos y el 100%\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_tree_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parece que el modelo aún podría beneficiarse de un incremento en el número de datos tanto en train como a la hora de generalizar, pero sobretodo a la hora de generalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a probar si un incremento de las particiones podría mejorar el modelo. Decision Tree con 12 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=12, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_tree_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Se obtienen las mismas conclusiones que en el caso anterior, pero quizás ahora más claras al utilizar mayor número de datos para hacer el entrenamiento y menor numero de datos para las validaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest con 5 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_RF_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest con 12 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=12, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_RF_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En el caso del Random Forest, las conclusiones son similares a las obtenidas por Decision Tree, pero con un peor resultado de las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier con 5 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_GBC_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBC con 12 particiones en CV\n",
    "cv = StratifiedKFold(n_splits=12, random_state=0)\n",
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf_GBC_gs_f1, cv=cv, train_sizes=sizes,\n",
    "    scoring='f1', n_jobs=4, X=X_train, y=y_train\n",
    ")\n",
    "\n",
    "viz.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En el caso de GBC, podemos ver que con pocos datos el modelo aprende los datos de train hasta conseguir un F1 Score del 100%, pero a medida que incrementa el número de datos, el modelo reduce el overfitting (generaliza mejor). Y parece que con mayor número de datos aún podría seguir mejorando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import DiscriminationThreshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A continuación vamos a ver si con una visualización de las métricas del modelo podemos conseguir una mejor intuición del funcionamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "visualizer = DiscriminationThreshold(clf_tree_gs_f1)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.poof()     "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precision: Llama la atención que por muy elevado que sitúe el threshold, el modelo predice como cuentas que han contratado préstamos, cuentas que no lo han contratado. Además la subida tan pronunciada de la curva nos indica que para las cuentas que no han contratado préstamo el modelo tiende a asignar un valor bajo de probabilidad. A partir de ese punto el F1 Score se estabiliza.\n",
    "\n",
    "Recall: El modelo asigna probabilidad=1 a más del 60% de las cuentas que han contratado préstamos. La poca pendiente de la curva nos indica que las cuentas que han contratado préstamo tiende a conseguir probabilidades elevadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "visualizer = DiscriminationThreshold(clf_RF_gs_f1)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precision: A partir de algon menos del 80% de probabilidad, todos los valores se corresponden a cuentas que han contratado préstamos, ya que la precisión es del 100%. Esto es muy positivo porque se asignan valores altos de probabilidad a las observaciones que efectivamente han contratado préstamos.\n",
    "\n",
    "Recall: Parece una curva con pendiente -1 o equivalentemente que la distribución de las probabilidades de las cuentas que han contratado préstamos es casi una uniforme entre las probabilidades 0% y 100%. Por lo tanto este modelo no consigue discriminar las cuentas que contratan préstamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "visualizer = DiscriminationThreshold(clf_GBC_gs_f1)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A diferencia de los modelos anteriores, el modelo obtenido con GBC tiene un threshold muy bajo. En este caso asigna probabilidades muy bajas a las cuentas que no han contratado préstamo y probabilidades a partir de 15% aprox para los casos que si han contratado préstamo.\n",
    "\n",
    "Precision: La curva tiene pendiente muy elevada indicando una notable discriminación de las cuentas que tienen préstamo, respecto de las que no lo tienen.\n",
    "\n",
    "Recall: La curva tiene una pendiente baja (excepto para valores muy cercanos al 100%) indicando que las cuentas que contratan préstamos tienden a tener probabilidades elevadas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
